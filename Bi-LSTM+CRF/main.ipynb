{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from config import parse_args\n",
    "\n",
    "args = parse_args()\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "setup_seed(args.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    6000 non-null   object\n",
      " 1   tag     6000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                         text          tag\n0   会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。       [会安古镇]\n1                                   贝蒂斯vs西班牙人  [贝蒂斯, 西班牙人]\n2        最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，        [橘子熊]\n3  2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing         [北京]\n4                        光谱代理《大战略PERFECT3》繁体版         [光谱]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。</td>\n      <td>[会安古镇]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>贝蒂斯vs西班牙人</td>\n      <td>[贝蒂斯, 西班牙人]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，</td>\n      <td>[橘子熊]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing</td>\n      <td>[北京]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>光谱代理《大战略PERFECT3》繁体版</td>\n      <td>[光谱]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../dataset/train.csv'\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "df['tag'] = df['tag'].apply(lambda x: eval(x))\n",
    "df.info()\n",
    "\n",
    "df.head(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:00<00:00, 74072.68it/s]\n"
     ]
    }
   ],
   "source": [
    "bio_list = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    text = df['text'][i]\n",
    "    tags = df['tag'][i]\n",
    "    bios = ['O']*len(text)\n",
    "    for t in tags:\n",
    "        idx = text.find(t)\n",
    "        bios[idx] = 'B-0'\n",
    "        for j in range(idx+1, idx+len(t)):\n",
    "            bios[j] = 'I-0'\n",
    "    bio_list.append(bios)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df['bio'] = bio_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data = train_test_split(df, test_size = 0.2, random_state=args.seed)\n",
    "train_data.index = list(range(len(train_data)))\n",
    "valid_data.index = list(range(len(valid_data)))\n",
    "# print(len(train_data), len(valid_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# 将text和标注组合存进元组\n",
    "train_data['training_data'] = train_data.apply(lambda row: [list(row['text']), row['bio']], axis=1)\n",
    "valid_data['validating_data'] = valid_data.apply(lambda row: [list(row['text']), row['bio']], axis=1)\n",
    "\n",
    "# test_data['testing_data'] = test_data.apply(lambda row: list(row['text']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： 4800\n",
      "验证集大小： 1200\n"
     ]
    }
   ],
   "source": [
    "training_data_txt = train_data['training_data'].to_list()\n",
    "validating_data_txt = valid_data['validating_data'].to_list()\n",
    "# testing_data_txt = test_data['testing_data'].to_list()\n",
    "print('训练集大小：',len(training_data_txt))\n",
    "print('验证集大小：',len(validating_data_txt))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_len:  3040\n"
     ]
    }
   ],
   "source": [
    "# --------------------------建立字典，字: idx-------------------------------------\n",
    "word2idx = {}\n",
    "# 训练集的\n",
    "for sentence, tags in training_data_txt:\n",
    "    for word in sentence:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "# 验证集的\n",
    "for sentence, tags in validating_data_txt:\n",
    "    for word in sentence:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "# 测试集的\n",
    "# testing_data = testing_data_txt\n",
    "# for sentence in testing_data:\n",
    "#     for word in sentence:\n",
    "#         if word not in word2idx:\n",
    "#             word2idx[word] = len(word2idx)\n",
    "\n",
    "# 加2个特殊字符\n",
    "word2idx['<UNK>'] = len(word2idx)\n",
    "word2idx['<PAD>'] = len(word2idx)\n",
    "\n",
    "args.word2idx = word2idx\n",
    "import pickle\n",
    "with open('./word2idx.pkl', 'wb') as f:\n",
    "    pickle.dump(args.word2idx, f)\n",
    "\n",
    "\n",
    "args.vocab_len = len(word2idx)\n",
    "\n",
    "print('vocab_len: ', args.vocab_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "args.tag2idx = {'O':0, 'B-0':1, 'I-0':2}\n",
    "args.idx2tag = {0: 'O', 1: 'B-0', 2:'I-0'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# training_data_txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from data_helper import create_data_loader\n",
    "train_data_loader = create_data_loader(training_data_txt, args)\n",
    "valid_data_loader = create_data_loader(validating_data_txt, args)\n",
    "# test_data_loader = create_data_loader(testing_data_txt, configs) # 没有标签的测试集就不这样构建，因为没有label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(300, 75)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader),len(valid_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def jaccard_score(pred, label):\n",
    "    return len(set(pred) & set(label)) / len(set(pred) | set(label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, args):\n",
    "    # 训练模式\n",
    "    model = model.train()\n",
    "    train_loss = 0\n",
    "    for sample in tqdm(data_loader):\n",
    "        sentence_tensor = sample['sentence_tensor'].to(args.device)\n",
    "        mask_tensor = sample['mask_tensor'].to(args.device)\n",
    "        label_tensor = sample['label_tensor'].to(args.device)\n",
    "        # print(sentence_tensor)\n",
    "        # print(mask_tensor)\n",
    "        # print(label_tensor)\n",
    "        out, loss = model(sentence_tensor=sentence_tensor,\n",
    "                        label_tensor=label_tensor,\n",
    "                        mask_tensor=mask_tensor)\n",
    "        # print(out)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return train_loss/len(data_loader)\n",
    "\n",
    "from ark_nlp.factory.utils.conlleval import get_entity_bio\n",
    "def return_entity(label):\n",
    "    entity_labels = []\n",
    "    for _type, _start_idx, _end_idx in get_entity_bio(label, id2label=None):\n",
    "            entity_labels.append({\n",
    "                'start_idx': _start_idx,\n",
    "                'end_idx': _end_idx,\n",
    "                'type': _type\n",
    "            })\n",
    "    entity_labels = [str(dic['start_idx'])+'-'+str(dic['end_idx']) for dic in entity_labels]\n",
    "    return entity_labels\n",
    "\n",
    "\n",
    "def eval_epoch(model, data_loader, args):\n",
    "    # 验证模式\n",
    "    model = model.eval()\n",
    "    val_loss = 0\n",
    "    jc_score_list = []\n",
    "    # 关闭自动求导，省内存加速，因为是不是训练模式了，没必要求导\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(data_loader):\n",
    "            sentence_tensor = sample['sentence_tensor'].to(args.device)\n",
    "            mask_tensor = sample['mask_tensor'].to(args.device)\n",
    "            label_tensor = sample['label_tensor'].to(args.device)\n",
    "            out, loss = model(sentence_tensor=sentence_tensor,\n",
    "                        label_tensor=label_tensor,\n",
    "                        mask_tensor=mask_tensor)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "            predict_ids = out\n",
    "            # predict_ids\n",
    "            #%%\n",
    "            label_ids = sample['label_tensor'].numpy().tolist()\n",
    "\n",
    "            entity_all_label_ids = []\n",
    "            entity_all_predict_ids = []\n",
    "            for i in range(len(label_ids)):\n",
    "                tmp_label, tmp_predict = [], []\n",
    "                # 因为我crf有做mask所以这里的len(len(predict_tag[i]))是不带有pad的长度\n",
    "                for j in range(0, len(predict_ids[i])):\n",
    "                    tmp_label.append(args.idx2tag[label_ids[i][j]])\n",
    "                    tmp_predict.append(args.idx2tag[predict_ids[i][j]])\n",
    "                entity_all_label_ids.append(tmp_label)\n",
    "                entity_all_predict_ids.append(tmp_predict)\n",
    "\n",
    "\n",
    "            for label, pred in zip(entity_all_label_ids, entity_all_predict_ids):\n",
    "                label_entity = return_entity(label)\n",
    "                pred_entity = return_entity(pred)\n",
    "                jc_score_list.append(jaccard_score(pred=pred_entity, label=label_entity))\n",
    "\n",
    "    return val_loss/len(data_loader), np.mean(jc_score_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用： cuda:0  ing........\n"
     ]
    }
   ],
   "source": [
    "from model import BiLSTM_CRF\n",
    "import torch.optim as optim\n",
    "if torch.cuda.is_available():\n",
    "    args.device = 'cuda:0'\n",
    "    print('使用：', args.device,' ing........')\n",
    "model = BiLSTM_CRF(args).to(args.device)\n",
    "# 优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————————————————— Epoch 1/16 ————————————————————\n",
      "Train loss : 175.03\n",
      "\n",
      "val loss : 117.332\n",
      "jc_score: 0.434\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 2/16 ————————————————————\n",
      "Train loss : 85.81\n",
      "\n",
      "val loss : 89.803\n",
      "jc_score: 0.526\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 3/16 ————————————————————\n",
      "Train loss : 52.94\n",
      "\n",
      "val loss : 83.354\n",
      "jc_score: 0.594\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 4/16 ————————————————————\n",
      "Train loss : 33.87\n",
      "\n",
      "———————————————————— Epoch 5/16 ————————————————————\n",
      "Train loss : 23.72\n",
      "\n",
      "val loss : 86.901\n",
      "jc_score: 0.635\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 6/16 ————————————————————\n",
      "Train loss : 17.47\n",
      "\n",
      "———————————————————— Epoch 7/16 ————————————————————\n",
      "Train loss : 14.19\n",
      "\n",
      "———————————————————— Epoch 8/16 ————————————————————\n",
      "Train loss : 12.3\n",
      "\n",
      "———————————————————— Epoch 9/16 ————————————————————\n",
      "Train loss : 10.44\n",
      "\n",
      "val loss : 106.246\n",
      "jc_score: 0.638\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 10/16 ————————————————————\n",
      "Train loss : 9.28\n",
      "\n",
      "———————————————————— Epoch 11/16 ————————————————————\n",
      "Train loss : 8.74\n",
      "\n",
      "———————————————————— Epoch 12/16 ————————————————————\n",
      "Train loss : 7.84\n",
      "\n",
      "val loss : 119.58\n",
      "jc_score: 0.649\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 13/16 ————————————————————\n",
      "Train loss : 7.38\n",
      "\n",
      "———————————————————— Epoch 14/16 ————————————————————\n",
      "Train loss : 7.04\n",
      "\n",
      "———————————————————— Epoch 15/16 ————————————————————\n",
      "Train loss : 6.57\n",
      "\n",
      "———————————————————— Epoch 16/16 ————————————————————\n",
      "Train loss : 6.02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:23<00:00, 12.60it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 25.94it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.71it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 25.63it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.09it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 26.16it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.27it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 25.82it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.68it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 25.86it/s]\n",
      "100%|██████████| 300/300 [00:23<00:00, 12.76it/s]\n",
      "100%|██████████| 75/75 [00:03<00:00, 24.64it/s]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.09it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 25.08it/s]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.31it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 25.42it/s]\n",
      "100%|██████████| 300/300 [00:25<00:00, 11.70it/s]\n",
      "100%|██████████| 75/75 [00:03<00:00, 20.97it/s]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.33it/s]\n",
      "100%|██████████| 75/75 [00:03<00:00, 24.83it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.66it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 25.61it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.23it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 26.23it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.07it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 26.02it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.87it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 26.07it/s]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.45it/s]\n",
      "100%|██████████| 75/75 [00:03<00:00, 24.72it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.92it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 25.61it/s]\n"
     ]
    }
   ],
   "source": [
    "best_jc_score = 0\n",
    "for epoch in range(args.max_epochs):\n",
    "    print('——'*10, f'Epoch {epoch + 1}/{args.max_epochs}', '——'*10)\n",
    "    train_loss = train_epoch(model, train_data_loader, optimizer, args)\n",
    "    # #scheduler.step()\n",
    "    # print('-'*20)\n",
    "    print(f'Train loss : {round(train_loss, 2)}\\n')\n",
    "    val_loss, jc_score = eval_epoch(model, valid_data_loader, args)\n",
    "\n",
    "\n",
    "    if jc_score>best_jc_score:\n",
    "        best_jc_score = jc_score\n",
    "        print(f'val loss : {round(val_loss, 3)}')\n",
    "        print(f\"jc_score: {round(jc_score, 3)}\")\n",
    "        print('-'*20)\n",
    "        torch.save(model.state_dict(), './save_model/best_model.pth')\n",
    "        print('+'*6,'best save_model saved','+'*6)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}