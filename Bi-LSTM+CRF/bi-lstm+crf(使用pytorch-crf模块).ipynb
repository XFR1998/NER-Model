{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# bi-lstm+crf，使用pytorch-crf库实现crf，可cuda加速。\n",
    "\n",
    "数据集说明：\n",
    "\n",
    "1: B-BANK 代表银行实体的开始\n",
    "\n",
    "2: I-BANK 代表银行实体的内部\n",
    "\n",
    "3: B-PRODUCT 代表产品实体的开始\n",
    "\n",
    "4: I-PRODUCT 代表产品实体的内部\n",
    "\n",
    "5: O 代表不属于标注的范围\n",
    "\n",
    "6: B-COMMENTS_N 代表用户评论（名词）\n",
    "\n",
    "7: I-COMMENTS_N 代表用户评论（名词）实体的内部\n",
    "\n",
    "8: B-COMMENTS_ADJ 代表用户评论（形容词）\n",
    "\n",
    "9: I-COMMENTS_ADJ 代表用户评论（形容词）实体的内部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda能用\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchcrf import CRF\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('{}能用'.format(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('./train_data_public.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "train_data, valid_data = train_test_split(data, test_size = 0.2, random_state=42)\n",
    "train_data.index = list(range(len(train_data)))\n",
    "valid_data.index = list(range(len(valid_data)))\n",
    "test_data = pd.read_csv('./test_public.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text  \\\n0                                            封卡只是鸡的原因吗？   \n1                                       销卡后45天后等征信更新再申请   \n2                                             有8w多的，招行的   \n3     判决金额8.2，表示你需要还款8.2，至于你是一次性还款，还是分期还款，如果判决书里没有具体...   \n4     我的-个人资料-联系地址??，刚瞅了眼我自己的信息，好像也乱了，我都怀疑前几天e分期一直秒拒...   \n...                                                 ...   \n7995                    座机：0000－00000000我四大行线上申请都是填这个！没   \n7996  私行，钻石，白金，金卡可以让理财经理挑(但是最多也就是3A/4A连号)，普卡也是可以让理财帮...   \n7997                                那你运气真不行??邀请短信很少不提的…   \n7998                             为什么我感觉这个帖子，我看过了，是说工行的么   \n7999                                     隔壁农行也这样{:1_1:}   \n\n                                               BIO_anno  class bank_topic  \n0             B-COMMENTS_N I-COMMENTS_N O O O O O O O O      2       交通银行  \n1     B-COMMENTS_N I-COMMENTS_N O O O O O O B-PRODUC...      2       建设银行  \n2                           O O O O O O B-BANK I-BANK O      2        NaN  \n3     O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O ...      2       工商银行  \n4     O O O O O O O O O O O O O O O O O O O O O O O ...      2        NaN  \n...                                                 ...    ...        ...  \n7995  O O O O O O O O O O O O O O O O O O O O O O O ...      2        NaN  \n7996  O O O O O O O O O O O O O O B-PRODUCT I-PRODUC...      2       工商银行  \n7997  O O O O O B-COMMENTS_ADJ I-COMMENTS_ADJ O O O ...      2        NaN  \n7998  O O O O O O O O O O O O O O O O O O B-BANK I-B...      2        NaN  \n7999              O O B-BANK I-BANK O O O O O O O O O O      2       中国银行  \n\n[8000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>BIO_anno</th>\n      <th>class</th>\n      <th>bank_topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>封卡只是鸡的原因吗？</td>\n      <td>B-COMMENTS_N I-COMMENTS_N O O O O O O O O</td>\n      <td>2</td>\n      <td>交通银行</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>销卡后45天后等征信更新再申请</td>\n      <td>B-COMMENTS_N I-COMMENTS_N O O O O O O B-PRODUC...</td>\n      <td>2</td>\n      <td>建设银行</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>有8w多的，招行的</td>\n      <td>O O O O O O B-BANK I-BANK O</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>判决金额8.2，表示你需要还款8.2，至于你是一次性还款，还是分期还款，如果判决书里没有具体...</td>\n      <td>O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O ...</td>\n      <td>2</td>\n      <td>工商银行</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>我的-个人资料-联系地址??，刚瞅了眼我自己的信息，好像也乱了，我都怀疑前几天e分期一直秒拒...</td>\n      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7995</th>\n      <td>座机：0000－00000000我四大行线上申请都是填这个！没</td>\n      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7996</th>\n      <td>私行，钻石，白金，金卡可以让理财经理挑(但是最多也就是3A/4A连号)，普卡也是可以让理财帮...</td>\n      <td>O O O O O O O O O O O O O O B-PRODUCT I-PRODUC...</td>\n      <td>2</td>\n      <td>工商银行</td>\n    </tr>\n    <tr>\n      <th>7997</th>\n      <td>那你运气真不行??邀请短信很少不提的…</td>\n      <td>O O O O O B-COMMENTS_ADJ I-COMMENTS_ADJ O O O ...</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7998</th>\n      <td>为什么我感觉这个帖子，我看过了，是说工行的么</td>\n      <td>O O O O O O O O O O O O O O O O O O B-BANK I-B...</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7999</th>\n      <td>隔壁农行也这样{:1_1:}</td>\n      <td>O O B-BANK I-BANK O O O O O O O O O O</td>\n      <td>2</td>\n      <td>中国银行</td>\n    </tr>\n  </tbody>\n</table>\n<p>8000 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "count    8000.000000\nmean       21.005000\nstd        17.386108\nmin         1.000000\n25%        10.000000\n50%        16.000000\n75%        25.000000\nmax       278.000000\nName: text, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看看大概的文本长度，以便确定padding长度\n",
    "len_text = train_data['text'].apply(lambda x: len(list(x)))\n",
    "len_text.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['封', '卡', '只', '是', '鸡', '的', '原', '因', '吗', '？']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_data['text'][0]\n",
    "list(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8000 entries, 0 to 7999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        8000 non-null   object\n",
      " 1   BIO_anno    8000 non-null   object\n",
      " 2   class       8000 non-null   int64 \n",
      " 3   bank_topic  6124 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 570.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 0 to 1999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        2000 non-null   object\n",
      " 1   BIO_anno    2000 non-null   object\n",
      " 2   class       2000 non-null   int64 \n",
      " 3   bank_topic  1512 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 78.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5093 entries, 0 to 5092\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5093 non-null   int64 \n",
      " 1   text    5093 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 79.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "valid_data.info()\n",
    "test_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "              text                                           BIO_anno  class  \\\n0       封卡只是鸡的原因吗？          B-COMMENTS_N I-COMMENTS_N O O O O O O O O      2   \n1  销卡后45天后等征信更新再申请  B-COMMENTS_N I-COMMENTS_N O O O O O O B-PRODUC...      2   \n2        有8w多的，招行的                        O O O O O O B-BANK I-BANK O      2   \n\n  bank_topic  \n0       交通银行  \n1       建设银行  \n2        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>BIO_anno</th>\n      <th>class</th>\n      <th>bank_topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>封卡只是鸡的原因吗？</td>\n      <td>B-COMMENTS_N I-COMMENTS_N O O O O O O O O</td>\n      <td>2</td>\n      <td>交通银行</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>销卡后45天后等征信更新再申请</td>\n      <td>B-COMMENTS_N I-COMMENTS_N O O O O O O B-PRODUC...</td>\n      <td>2</td>\n      <td>建设银行</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>有8w多的，招行的</td>\n      <td>O O O O O O B-BANK I-BANK O</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 把text和标注按单个字分隔开，放进列表\n",
    "train_data['BIO_anno'] = train_data['BIO_anno'].apply(lambda x:x.split(' '))\n",
    "valid_data['BIO_anno'] = valid_data['BIO_anno'].apply(lambda x:x.split(' '))\n",
    "# 将text和标注组合存进元组\n",
    "train_data['training_data'] = train_data.apply(lambda row: [list(row['text']), row['BIO_anno']], axis=1)\n",
    "valid_data['validating_data'] = valid_data.apply(lambda row: [list(row['text']), row['BIO_anno']], axis=1)\n",
    "test_data['testing_data'] = test_data.apply(lambda row: list(row['text']), axis=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "num = train_data['training_data'].apply(lambda x:type(x[0])!=type([]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： 8000\n",
      "验证集大小： 2000\n",
      "测试集大小： 5093\n"
     ]
    }
   ],
   "source": [
    "training_data_txt = train_data['training_data'].to_list()\n",
    "validating_data_txt = valid_data['validating_data'].to_list()\n",
    "testing_data_txt = test_data['testing_data'].to_list()\n",
    "print('训练集大小：',len(training_data_txt))\n",
    "print('验证集大小：',len(validating_data_txt))\n",
    "print('测试集大小：',len(testing_data_txt))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 定义一些工具函数\n",
    "\n",
    "# 句子转idx\n",
    "def prepare_sequence(seq, word2idx):\n",
    "    idxs = [word2idx[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    # 返回vec的dim为1维度上的最大值索引\n",
    "    _, idx = torch.max(vec,axis=1)\n",
    "    return idx.item()\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "# 前向算法是不断累积之前的结果，这样就会有个缺点\n",
    "# 指数和累积到一定程度后，会超过计算机浮点值的最大值，变成inf，这样取log后也是inf\n",
    "# 为了避免这种情况，用一个合适的值clip去提指数和的公因子，这样就不会使某项变得过大而无法计算\n",
    "# SUM = log(exp(s1)+exp(s2)+...+exp(s100))\n",
    "#     = log{exp(clip)*[exp(s1-clip)+exp(s2-clip)+...+exp(s100-clip)]}\n",
    "#     = clip + log[exp(s1-clip)+exp(s2-clip)+...+exp(s100-clip)]\n",
    "# where clip=max\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.configs = configs\n",
    "        # if config.embedding_pretrained is not None:\n",
    "        #     self.embedding = nn.Embedding.from_pretrained(configs.embedding_pretrained,\n",
    "        #                                                   freeze=False)  # 表示训练过程词嵌入向量会更新\n",
    "        # else:\n",
    "\n",
    "        self.embedding = nn.Embedding(configs.vocab_len, configs.embedding_dim,\n",
    "                                      padding_idx=configs.word2idx['<PAD>'])  # PAD索引填充\n",
    "\n",
    "        if configs.bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=configs.embedding_dim,\n",
    "                           hidden_size=configs.hidden_size,\n",
    "                           num_layers=configs.num_layers,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=configs.bidirectional)\n",
    "\n",
    "        self.tag2idx = configs.tag2idx\n",
    "\n",
    "        # 转换参数矩阵 输入i,j是得分从j转换到i\n",
    "        self.tagset_size = len(self.tag2idx)\n",
    "        # 将lstm的输出映射到标记空间\n",
    "        self.hidden2tag = nn.Linear(configs.hidden_size*self.num_directions, self.tagset_size)  # -> (B, num_class+2)  加上了START END\n",
    "        self.crf = CRF(num_tags=self.tagset_size,batch_first=True)\n",
    "\n",
    "    def _init_hidden(self, batchs):  # 初始化h_0和c_0 与GRU不同的是多了c_0（细胞状态）\n",
    "        h_0 = torch.randn(self.configs.num_layers*self.num_directions, batchs,  self.configs.hidden_size)\n",
    "        c_0 = torch.randn(self.configs.num_layers*self.num_directions, batchs, self.configs.hidden_size)\n",
    "        return self._make_tensor(h_0), self._make_tensor(c_0)\n",
    "\n",
    "    def _get_lstm_features(self, x):\n",
    "        # x.shape: (bs, num_words)\n",
    "        x = self.embedding(x)\n",
    "        # x.shape: (bs, num_words, embedding_dim)\n",
    "        h_0, c_0 = self._init_hidden(batchs=x.size(0))\n",
    "        out, (hidden, c) = self.rnn(x,(h_0, c_0))\n",
    "        # out.shape: (bs, num_words, hidden_size*2)\n",
    "        out = self.hidden2tag(out)  # (B,num_directions*hidden_size) -> (B, num_class)\n",
    "        # out.shape: (bs, num_words, tagset_size)\n",
    "        return out\n",
    "\n",
    "    def neg_log_likelihood(self, sentence_tensor=None, label_tensor=None, mask_tensor=None):  # 损失函数\n",
    "        feats = self._get_lstm_features(sentence_tensor)\n",
    "        return -self.crf(emissions=feats, tags=label_tensor, mask=mask_tensor)\n",
    "        # return -self.crf(emissions=feats, tags=label_tensor)\n",
    "\n",
    "\n",
    "    def _make_tensor(self, tensor):\n",
    "        # 函数说明： 将传入的tensor转移到cpu或gpu内\n",
    "        tensor_ret = tensor.to(self.configs.device)\n",
    "        return tensor_ret\n",
    "\n",
    "\n",
    "    def forward(self, sentence_tensor=None, mask_tensor=None):\n",
    "        # 数据预处理时，x被处理成是一个tuple,其内容是: (word, label).\n",
    "        # x:b_size\n",
    "        # print(sentence_tensor)\n",
    "        # print(mask_tensor)\n",
    "        lstm_feats = self._get_lstm_features(sentence_tensor)  # 获取BiLSTM的emission分数\n",
    "\n",
    "        # Returns: List of list containing the best tag sequence for each batch.\n",
    "        # 返回列表组成的标签\n",
    "\n",
    "        out = self.crf.decode(emissions=lstm_feats,\n",
    "                              mask=mask_tensor)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from utils.param_configs import Configs\n",
    "configs = Configs()\n",
    "\n",
    "# 将训练集汉字使用数字表示\n",
    "# 为了方便调试，先用100条数据进行训练，调试好后可用全量数据进行训练\n",
    "# training_data_txt = training_data_txt[:]\n",
    "# --------------------------建立字典，字: idx-------------------------------------\n",
    "word2idx = {}\n",
    "# 训练集的\n",
    "for sentence, tags in training_data_txt:\n",
    "    for word in sentence:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "# 验证集的\n",
    "for sentence, tags in validating_data_txt:\n",
    "    for word in sentence:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "# 测试集的\n",
    "testing_data = testing_data_txt\n",
    "for sentence in testing_data:\n",
    "    for word in sentence:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "# 加2个特殊字符\n",
    "word2idx['<UNK>'] = len(word2idx)\n",
    "word2idx['<PAD>'] = len(word2idx)\n",
    "\n",
    "configs.word2idx = word2idx\n",
    "configs.vocab_len = len(word2idx)\n",
    "# ------------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "8000"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_txt[0][0]),len(training_data_txt[0][1])\n",
    "len(training_data_txt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from utils.data_process import create_data_loader\n",
    "train_data_loader = create_data_loader(training_data_txt, configs)\n",
    "valid_data_loader = create_data_loader(validating_data_txt, configs)\n",
    "# test_data_loader = create_data_loader(testing_data_txt, configs) # 没有标签的测试集就不这样构建，因为没有label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(500, 125)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader),len(valid_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': ['封 卡 只 是 鸡 的 原 因 吗 ？ <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', '销 卡 后 4 5 天 后 等 征 信 更 新 再 申 请 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', '有 8 w 多 的 ， 招 行 的 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', '判 决 金 额 8 . 2 ， 表 示 你 需 要 还 款 8 . 2 ， 至 于 你 是 一 次 性 还 款 ， 还', '我 的 - 个 人 资 料 - 联 系 地 址 ? ? ， 刚 瞅 了 眼 我 自 己 的 信 息 ， 好 像 也 乱', '这 短 信 只 是 系 统 统 一 默 认 的 ， 短 信 提 示 制 卡 中 其 实 也 就 是 等 于 数 字 卡', '我 固 定 额 度 3 0 0 0 0 , 现 金 分 期 1 2 0 0 0 0 ！ <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', '求 哥 哥 帮 忙 。 到 了 这 个 界 面 还 会 被 拒 绝 吗 ？ 刷 脸 要 等 2 4 小 时 。 <PAD> <PAD>', '最 近 我 刷 了 好 几 次 都 没 有 ， 机 器 换 了 几 台 也 没 有 封 卡 啊 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', '以 前 经 常 空 卡 ， 今 年 开 始 正 常 用 卡 ， 真 实 加 套 现 ， 留 2 0 % 以 上 额 度', '招 商 哪 个 大 功 能 需 要 盾 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', '应 该 可 以 吧 ， 我 的 资 质 一 般 ， 刚 毕 业 2 年 ， 招 行 卡 2 万 额 度 <PAD> <PAD> <PAD> <PAD>', '现 在 毕 业 不 止 6 万 了 吗 ？ 我 自 然 升 到 6 万 两 三 年 了 也 没 动 静 <PAD> <PAD> <PAD> <PAD>', '缓 冲 期 什 么 意 思 啊 ， 而 且 我 工 行 信 用 卡 一 个 月 都 花 不 了 3 0 0 块 钱 怎', '初 审 黑 炭 都 能 过 就 是 审 核 没 过 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', '正 常 用 卡 一 张 就 够 ? ? 留 两 张 额 度 高 的 以 防 日 后 有 资 金 需 求 卡 少 方 便'], 'label': ['B-COMMENTS_N I-COMMENTS_N O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'B-COMMENTS_N I-COMMENTS_N O O O O O O B-PRODUCT I-PRODUCT O O O O O O O O O O O O O O O O O O O O', 'O O O O O O B-BANK I-BANK O O O O O O O O O O O O O O O O O O O O O O', 'O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-COMMENTS_ADJ', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O B-PRODUCT I-PRODUCT O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O B-COMMENTS_ADJ I-COMMENTS_ADJ O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O O O O O O', 'O O O O O O O O O O O B-COMMENTS_ADJ I-COMMENTS_ADJ O O O O O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N', 'B-BANK I-BANK O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O B-BANK I-BANK O O O O O O O O O', 'O O O O O O O O O O O O O O B-COMMENTS_ADJ O O O O O O O O B-COMMENTS_ADJ I-COMMENTS_ADJ I-COMMENTS_ADJ O O O O', 'O O O O O O O O O O O O B-BANK I-BANK B-PRODUCT I-PRODUCT I-PRODUCT O O O O O O O O O O O O O', 'O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O O O O O O O O O O O O', 'B-COMMENTS_ADJ I-COMMENTS_ADJ O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N B-COMMENTS_ADJ O O O O O O O O O O O O O O'], 'sentence_tensor': tensor([[   0,    1,    2,    3,    4,    5,    6,    7,    8,    9, 2621, 2621,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621],\n",
      "        [  10,    1,   11,   12,   13,   14,   11,   15,   16,   17,   18,   19,\n",
      "           20,   21,   22, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621],\n",
      "        [  23,   24,   25,   26,    5,   27,   28,   29,    5, 2621, 2621, 2621,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621],\n",
      "        [  30,   31,   32,   33,   24,   34,   35,   27,   36,   37,   38,   39,\n",
      "           40,   41,   42,   24,   34,   35,   27,   43,   44,   38,    3,   45,\n",
      "           46,   47,   41,   42,   27,   41],\n",
      "        [  67,    5,   68,   69,   70,   71,   72,   68,   73,   74,   75,   76,\n",
      "           77,   77,   27,   78,   79,   80,   81,   67,   82,   83,    5,   17,\n",
      "           84,   27,   85,   86,   87,   88],\n",
      "        [ 108,  109,   17,    2,    3,   74,  110,  110,   45,  111,  112,    5,\n",
      "           27,  109,   17,  113,   37,  114,    1,  115,  116,  117,   87,   98,\n",
      "            3,   15,   44,  118,  119,    1],\n",
      "        [  67,  133,  134,   33,  135,  136,  137,  137,  137,  137,  138,  139,\n",
      "           32,   48,   49,  140,   35,  137,  137,  137,  137,  132, 2621, 2621,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621],\n",
      "        [ 141,  142,  142,  143,  144,   66,  145,   80,  108,   69,  146,  147,\n",
      "           41,  148,  149,   97,  150,    8,    9,  151,  152,   40,   15,   35,\n",
      "           12,  153,  103,   66, 2621, 2621],\n",
      "        [ 127,  154,   67,  151,   80,   85,   93,   46,   89,   54,   23,   27,\n",
      "          155,  156,  157,   80,   93,  158,   87,   54,   23,    0,    1,  159,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621],\n",
      "        [  61,   92,  160,  161,  162,    1,   27,  163,  164,  165,  166,  120,\n",
      "          161,  167,    1,   27,  168,  117,  169,  170,  139,   27,  171,   35,\n",
      "          137,  172,   61,  173,   33,  135],\n",
      "        [  28,   65,  178,   69,  179,  180,  181,   39,   40,  182, 2621, 2621,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621],\n",
      "        [ 183,  184,   60,   61,  185,   27,   67,    5,   71,  186,   45,  187,\n",
      "           27,   78,  188,  189,   35,  164,   27,   28,   29,    1,   35,  190,\n",
      "           33,  135, 2621, 2621, 2621, 2621],\n",
      "        [ 139,  121,  188,  189,  191,  192,  193,  190,   80,    8,    9,   67,\n",
      "           82,  194,  195,  145,  193,  190,  196,  197,  164,   80,   87,   54,\n",
      "          176,  177, 2621, 2621, 2621, 2621],\n",
      "        [ 198,  199,   49,  200,  201,  125,  126,  159,   27,  202,  203,   67,\n",
      "          204,   29,   17,  167,    1,   45,   69,  175,   89,  205,  191,   80,\n",
      "          136,  137,  137,  206,  207,  208],\n",
      "        [ 211,  212,  213,  214,   89,  181,  215,   98,    3,  212,  216,   54,\n",
      "          215, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n",
      "         2621, 2621, 2621, 2621, 2621, 2621],\n",
      "        [ 120,  161,  167,    1,   45,  217,   98,  218,   77,   77,  171,  196,\n",
      "          217,   33,  135,  219,    5,   61,  220,  221,   11,   23,   71,   32,\n",
      "           39,  141,    1,  222,  223,  224]]), 'label_tensor': tensor([[5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [5, 6, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 5, 6, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 7],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 5, 6],\n",
      "        [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7,\n",
      "         8, 8, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'mask_tensor': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])}\n"
     ]
    }
   ],
   "source": [
    "for sample in train_data_loader:\n",
    "    print(sample)\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "500"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "configs.word2idx['封']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "['封 卡 只 是 鸡 的 原 因 吗 ？ <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '销 卡 后 4 5 天 后 等 征 信 更 新 再 申 请 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '有 8 w 多 的 ， 招 行 的 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '判 决 金 额 8 . 2 ， 表 示 你 需 要 还 款 8 . 2 ， 至 于 你 是 一 次 性 还 款 ， 还',\n '我 的 - 个 人 资 料 - 联 系 地 址 ? ? ， 刚 瞅 了 眼 我 自 己 的 信 息 ， 好 像 也 乱',\n '这 短 信 只 是 系 统 统 一 默 认 的 ， 短 信 提 示 制 卡 中 其 实 也 就 是 等 于 数 字 卡',\n '我 固 定 额 度 3 0 0 0 0 , 现 金 分 期 1 2 0 0 0 0 ！ <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '求 哥 哥 帮 忙 。 到 了 这 个 界 面 还 会 被 拒 绝 吗 ？ 刷 脸 要 等 2 4 小 时 。 <PAD> <PAD>',\n '最 近 我 刷 了 好 几 次 都 没 有 ， 机 器 换 了 几 台 也 没 有 封 卡 啊 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '以 前 经 常 空 卡 ， 今 年 开 始 正 常 用 卡 ， 真 实 加 套 现 ， 留 2 0 % 以 上 额 度',\n '招 商 哪 个 大 功 能 需 要 盾 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '应 该 可 以 吧 ， 我 的 资 质 一 般 ， 刚 毕 业 2 年 ， 招 行 卡 2 万 额 度 <PAD> <PAD> <PAD> <PAD>',\n '现 在 毕 业 不 止 6 万 了 吗 ？ 我 自 然 升 到 6 万 两 三 年 了 也 没 动 静 <PAD> <PAD> <PAD> <PAD>',\n '缓 冲 期 什 么 意 思 啊 ， 而 且 我 工 行 信 用 卡 一 个 月 都 花 不 了 3 0 0 块 钱 怎',\n '初 审 黑 炭 都 能 过 就 是 审 核 没 过 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '正 常 用 卡 一 张 就 够 ? ? 留 两 张 额 度 高 的 以 防 日 后 有 资 金 需 求 卡 少 方 便']"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sentence']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "['B-COMMENTS_N I-COMMENTS_N O O O O O O O O O O O O O O O O O O O O O O O O O O O O',\n 'B-COMMENTS_N I-COMMENTS_N O O O O O O B-PRODUCT I-PRODUCT O O O O O O O O O O O O O O O O O O O O',\n 'O O O O O O B-BANK I-BANK O O O O O O O O O O O O O O O O O O O O O O',\n 'O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O',\n 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-COMMENTS_ADJ',\n 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O',\n 'O O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O B-PRODUCT I-PRODUCT O O O O O O O O O O O O O O O',\n 'O O O O O O O O O O O O O O O B-COMMENTS_ADJ I-COMMENTS_ADJ O O O O O O O O O O O O O',\n 'O O O O O O O O O O O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O O O O O O',\n 'O O O O O O O O O O O B-COMMENTS_ADJ I-COMMENTS_ADJ O O O O O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N',\n 'B-BANK I-BANK O O O O O O O O O O O O O O O O O O O O O O O O O O O O',\n 'O O O O O O O O O O O O O O O O O O O B-BANK I-BANK O O O O O O O O O',\n 'O O O O O O O O O O O O O O B-COMMENTS_ADJ O O O O O O O O B-COMMENTS_ADJ I-COMMENTS_ADJ I-COMMENTS_ADJ O O O O',\n 'O O O O O O O O O O O O B-BANK I-BANK B-PRODUCT I-PRODUCT I-PRODUCT O O O O O O O O O O O O O',\n 'O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O O O O O O O O O O O O',\n 'B-COMMENTS_ADJ I-COMMENTS_ADJ O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N B-COMMENTS_ADJ O O O O O O O O O O O O O O']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['label']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[   0,    1,    2,    3,    4,    5,    6,    7,    8,    9, 2621, 2621,\n         2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n         2621, 2621, 2621, 2621, 2621, 2621],\n        [  10,    1,   11,   12,   13,   14,   11,   15,   16,   17,   18,   19,\n           20,   21,   22, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n         2621, 2621, 2621, 2621, 2621, 2621],\n        [  23,   24,   25,   26,    5,   27,   28,   29,    5, 2621, 2621, 2621,\n         2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n         2621, 2621, 2621, 2621, 2621, 2621],\n        [  30,   31,   32,   33,   24,   34,   35,   27,   36,   37,   38,   39,\n           40,   41,   42,   24,   34,   35,   27,   43,   44,   38,    3,   45,\n           46,   47,   41,   42,   27,   41],\n        [  67,    5,   68,   69,   70,   71,   72,   68,   73,   74,   75,   76,\n           77,   77,   27,   78,   79,   80,   81,   67,   82,   83,    5,   17,\n           84,   27,   85,   86,   87,   88],\n        [ 108,  109,   17,    2,    3,   74,  110,  110,   45,  111,  112,    5,\n           27,  109,   17,  113,   37,  114,    1,  115,  116,  117,   87,   98,\n            3,   15,   44,  118,  119,    1],\n        [  67,  133,  134,   33,  135,  136,  137,  137,  137,  137,  138,  139,\n           32,   48,   49,  140,   35,  137,  137,  137,  137,  132, 2621, 2621,\n         2621, 2621, 2621, 2621, 2621, 2621],\n        [ 141,  142,  142,  143,  144,   66,  145,   80,  108,   69,  146,  147,\n           41,  148,  149,   97,  150,    8,    9,  151,  152,   40,   15,   35,\n           12,  153,  103,   66, 2621, 2621],\n        [ 127,  154,   67,  151,   80,   85,   93,   46,   89,   54,   23,   27,\n          155,  156,  157,   80,   93,  158,   87,   54,   23,    0,    1,  159,\n         2621, 2621, 2621, 2621, 2621, 2621],\n        [  61,   92,  160,  161,  162,    1,   27,  163,  164,  165,  166,  120,\n          161,  167,    1,   27,  168,  117,  169,  170,  139,   27,  171,   35,\n          137,  172,   61,  173,   33,  135],\n        [  28,   65,  178,   69,  179,  180,  181,   39,   40,  182, 2621, 2621,\n         2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n         2621, 2621, 2621, 2621, 2621, 2621],\n        [ 183,  184,   60,   61,  185,   27,   67,    5,   71,  186,   45,  187,\n           27,   78,  188,  189,   35,  164,   27,   28,   29,    1,   35,  190,\n           33,  135, 2621, 2621, 2621, 2621],\n        [ 139,  121,  188,  189,  191,  192,  193,  190,   80,    8,    9,   67,\n           82,  194,  195,  145,  193,  190,  196,  197,  164,   80,   87,   54,\n          176,  177, 2621, 2621, 2621, 2621],\n        [ 198,  199,   49,  200,  201,  125,  126,  159,   27,  202,  203,   67,\n          204,   29,   17,  167,    1,   45,   69,  175,   89,  205,  191,   80,\n          136,  137,  137,  206,  207,  208],\n        [ 211,  212,  213,  214,   89,  181,  215,   98,    3,  212,  216,   54,\n          215, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621, 2621,\n         2621, 2621, 2621, 2621, 2621, 2621],\n        [ 120,  161,  167,    1,   45,  217,   98,  218,   77,   77,  171,  196,\n          217,   33,  135,  219,    5,   61,  220,  221,   11,   23,   71,   32,\n           39,  141,    1,  222,  223,  224]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sentence_tensor']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n        False, False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False, False])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['mask_tensor'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['label_tensor'][-6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color='red'>Model Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, scheduler, configs):\n",
    "    # 训练模式\n",
    "    model = model.train()\n",
    "    loss_list = []\n",
    "    for sample in tqdm(data_loader, 'train'):\n",
    "        sentence_tensor = sample['sentence_tensor'].to(configs.device)\n",
    "        mask_tensor = sample['mask_tensor'].to(configs.device)\n",
    "        label_tensor = sample['label_tensor'].to(configs.device)\n",
    "        # print(sentence_tensor)\n",
    "        # print(mask_tensor)\n",
    "        # print(label_tensor)\n",
    "        out = model(sentence_tensor, mask_tensor)\n",
    "        # print(out)\n",
    "        loss = model.neg_log_likelihood(sentence_tensor=sentence_tensor,\n",
    "                                        label_tensor=label_tensor,\n",
    "                                        mask_tensor=mask_tensor)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return np.mean(loss_list)\n",
    "\n",
    "\n",
    "def eval_epoch(model, data_loader, configs):\n",
    "    # 验证模式\n",
    "    model = model.eval()\n",
    "    loss_list = []\n",
    "    # 关闭自动求导，省内存加速，因为是不是训练模式了，没必要求导\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(data_loader, 'val'):\n",
    "            sentence_tensor = sample['sentence_tensor'].to(configs.device)\n",
    "            mask_tensor = sample['mask_tensor'].to(configs.device)\n",
    "            label_tensor = sample['label_tensor'].to(configs.device)\n",
    "            out = model(sentence_tensor, mask_tensor)\n",
    "            loss = model.neg_log_likelihood(sentence_tensor=sentence_tensor,\n",
    "                                            label_tensor=label_tensor,\n",
    "                                            mask_tensor=mask_tensor)\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "\n",
    "    return np.mean(loss_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "model = BiLSTM_CRF(configs).to(device)\n",
    "# 优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# 学习率指数衰减  每个epoch: lr = gamma*lr\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "# 损失函数。这个倒是不用定义了，因为pytorch-crf的crf自带loss的计算\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "EPOCHS = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————————————————— Epoch 1/2 ————————————————————\n",
      "Train loss : 236.79\n",
      "Val loss : 235.08\n",
      "———————————————————— Epoch 2/2 ————————————————————\n",
      "Train loss : 229.41\n",
      "Val loss : 234.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 500/500 [00:20<00:00, 23.88it/s]\n",
      "val: 100%|██████████| 125/125 [00:02<00:00, 47.42it/s]\n",
      "train: 100%|██████████| 500/500 [00:20<00:00, 24.86it/s]\n",
      "val: 100%|██████████| 125/125 [00:02<00:00, 48.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print('——'*10, f'Epoch {epoch + 1}/{EPOCHS}', '——'*10)\n",
    "    train_loss = train_epoch(model, train_data_loader, optimizer,scheduler, configs)\n",
    "    print(f'Train loss : {round(train_loss, 2)}')\n",
    "\n",
    "    val_loss = eval_epoch(model, valid_data_loader, configs)\n",
    "    print(f'Val loss : {round(val_loss, 2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# predict_tag = []\n",
    "# for l in out:\n",
    "#     temp = []\n",
    "#     for i in l:\n",
    "#         temp.append(configs.idx2tag[i])\n",
    "#     predict_tag.append(temp)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color='red'>test some instances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val:   0%|          | 0/125 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# 验证模式\n",
    "model = model.eval()\n",
    "loss_list = []\n",
    "# 关闭自动求导，省内存加速，因为是不是训练模式了，没必要求导\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(valid_data_loader, 'val'):\n",
    "        sentence_tensor = sample['sentence_tensor'].to(configs.device)\n",
    "        mask_tensor = sample['mask_tensor'].to(configs.device)\n",
    "        label_tensor = sample['label_tensor'].to(configs.device)\n",
    "        out = model(sentence_tensor, mask_tensor)\n",
    "        predict_tag = []\n",
    "        for l in out:\n",
    "            temp = []\n",
    "            for i in l:\n",
    "                temp.append(configs.idx2tag[i])\n",
    "            predict_tag.append(temp)\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(15, 13, 30)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(predict_tag[0]),len(predict_tag[1]),len(predict_tag[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  63,   29,  191,  148, 1826],\n        [ 178,   53,   60,   61,  283],\n        [1118,   14,  532,   17,    5],\n        [ 127,  222,   40,  140,   69],\n        [ 473,   38,   69,  100,  952],\n        [ 479,  532,   17,   27,  372],\n        [1050,   54,   23,  215,  367],\n        [1466,  527,    2,  181,  167],\n        [ 115,   29,  547,  175,   23],\n        [ 718,   92,   41,  191,  145],\n        [ 450,   27,   64,   65,   85],\n        [ 183,  184,    3,  382,   14],\n        [  33,  135,   60,   61,   27],\n        [ 709,   45,  656,  709,  386],\n        [ 508,  190,   33,  135,   41],\n        [  38,    1,  145,   80,    8]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sentence_tensor']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n         False, False, False, False, False, False, False, False, False, False],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True, False, False, False, False, False],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n         False, False, False, False, False, False, False, False, False, False],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n         False, False, False, False, False, False, False, False, False, False],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True, False, False, False, False, False, False, False],\n        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['mask_tensor']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0, 0, 7, 8, 8, 8, 0, 0, 0, 7, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4,\n         7, 8, 8, 0, 0, 0],\n        [7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0,\n         0, 0, 0, 7, 0, 0],\n        [0, 0, 0, 0, 3, 4, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 7, 8, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 3, 4, 0, 0, 7, 8, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['label_tensor']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "['银 行 不 会 雪 中 送 炭 ， 只 会 锦 上 添 花 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '哪 里 可 以 看 到 我 有 没 有 拒 绝 ？ <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '昨 天 微 信 的 上 海 信 访 这 个 月 七 号 上 门 了 协 商 个 性 化 分 期 不 同 意 说 是 他',\n '最 少 要 1 个 半 月 ， 我 以 前 处 理 过 。 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '教 你 个 办 法 ， 信 不 信 由 你 ， 先 去 柜 台 人 工 申 请 e 分 期 ， 通 过 率 高 ， 只',\n '绑 微 信 ， 支 付 宝 ， 云 闪 付 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '冷 没 有 过 去 ? ? <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '境 外 只 能 用 支 付 宝 微 信 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '中 行 每 月 有 一 次 5 元 立 减 金 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '目 前 还 不 到 贷 款 。 有 很 多 询 问 。 你 有 网 贷 ， 不 敢 操 作 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '亲 ， 协 商 好 了 说 一 下 ， 我 情 况 和 你 差 不 多 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '应 该 是 当 天 只 查 一 次 征 信 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '额 度 可 以 ， 至 于 卡 面 ， 难 看 无 比 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '周 一 买 周 二 确 认 周 二 赎 回 周 三 到 账 一 个 轮 回 ， 周 三 到 账 再 购 买 周 四 确',\n '八 万 额 度 还 可 以 吧 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n '你 卡 到 了 吗 ， 农 业 银 行 速 度 很 慢 啊 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>']"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sentence']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}