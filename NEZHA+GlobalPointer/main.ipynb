{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup,BertConfig\n",
    "from ark_nlp.model.ner.global_pointer_bert import Tokenizer\n",
    "from ark_nlp.model.ner.global_pointer_bert import Dataset as Dt\n",
    "from ark_nlp.factory.utils.conlleval import get_entity_bio\n",
    "from model import GlobalPointer, GlobalPointerNERPredictor, GlobalPointerCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from config import parse_args\n",
    "\n",
    "args = parse_args()\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "setup_seed(args.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    6000 non-null   object\n",
      " 1   tag     6000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                         text          tag\n0   会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。       [会安古镇]\n1                                   贝蒂斯vs西班牙人  [贝蒂斯, 西班牙人]\n2        最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，        [橘子熊]\n3  2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing         [北京]\n4                        光谱代理《大战略PERFECT3》繁体版         [光谱]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。</td>\n      <td>[会安古镇]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>贝蒂斯vs西班牙人</td>\n      <td>[贝蒂斯, 西班牙人]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，</td>\n      <td>[橘子熊]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing</td>\n      <td>[北京]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>光谱代理《大战略PERFECT3》繁体版</td>\n      <td>[光谱]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../dataset/train.csv'\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "df['tag'] = df['tag'].apply(lambda x: eval(x))\n",
    "df.info()\n",
    "\n",
    "df.head(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:00<00:00, 118035.25it/s]\n"
     ]
    }
   ],
   "source": [
    "bio_list = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    text = df['text'][i]\n",
    "    tags = df['tag'][i]\n",
    "    bios = ['O']*len(text)\n",
    "    for t in tags:\n",
    "        idx = text.find(t)\n",
    "        bios[idx] = 'B-0'\n",
    "        for j in range(idx+1, idx+len(t)):\n",
    "            bios[j] = 'I-0'\n",
    "    bio_list.append(bios)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# bio_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df['BIO'] = bio_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "all_entity_labels = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    entity_labels=[]\n",
    "    for _type, _start_idx, _end_idx in get_entity_bio(df['BIO'][i], id2label=None):\n",
    "        entity_labels.append({\n",
    "            'start_idx': _start_idx,\n",
    "            'end_idx': _end_idx,\n",
    "            'type': _type,\n",
    "            'entity': df['text'][i][_start_idx: _end_idx + 1]\n",
    "        })\n",
    "    all_entity_labels.append(entity_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df['label'] = all_entity_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         text  \\\n0   会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。   \n1                                   贝蒂斯vs西班牙人   \n2        最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，   \n3  2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing   \n4                        光谱代理《大战略PERFECT3》繁体版   \n\n                                                 BIO  \\\n0  [O, O, O, O, O, O, O, O, O, B-0, I-0, I-0, I-0...   \n1          [B-0, I-0, I-0, O, O, B-0, I-0, I-0, I-0]   \n2  [O, O, B-0, I-0, I-0, O, O, O, O, O, O, O, O, ...   \n3  [O, O, O, O, O, O, O, O, O, O, O, O, B-0, I-0,...   \n4  [B-0, I-0, O, O, O, O, O, O, O, O, O, O, O, O,...   \n\n                                               label  \n0  [{'start_idx': 9, 'end_idx': 12, 'type': '0', ...  \n1  [{'start_idx': 0, 'end_idx': 2, 'type': '0', '...  \n2  [{'start_idx': 2, 'end_idx': 4, 'type': '0', '...  \n3  [{'start_idx': 12, 'end_idx': 13, 'type': '0',...  \n4  [{'start_idx': 0, 'end_idx': 1, 'type': '0', '...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>BIO</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。</td>\n      <td>[O, O, O, O, O, O, O, O, O, B-0, I-0, I-0, I-0...</td>\n      <td>[{'start_idx': 9, 'end_idx': 12, 'type': '0', ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>贝蒂斯vs西班牙人</td>\n      <td>[B-0, I-0, I-0, O, O, B-0, I-0, I-0, I-0]</td>\n      <td>[{'start_idx': 0, 'end_idx': 2, 'type': '0', '...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，</td>\n      <td>[O, O, B-0, I-0, I-0, O, O, O, O, O, O, O, O, ...</td>\n      <td>[{'start_idx': 2, 'end_idx': 4, 'type': '0', '...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-0, I-0,...</td>\n      <td>[{'start_idx': 12, 'end_idx': 13, 'type': '0',...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>光谱代理《大战略PERFECT3》繁体版</td>\n      <td>[B-0, I-0, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n      <td>[{'start_idx': 0, 'end_idx': 1, 'type': '0', '...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['tag'], axis=1)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： 4800\n",
      "验证集大小： 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data = train_test_split(df, test_size = 0.2, random_state=args.seed)\n",
    "train_data.index = list(range(len(train_data)))\n",
    "valid_data.index = list(range(len(valid_data)))\n",
    "train_data['label'] = train_data['label'].apply(lambda x: str(x))\n",
    "valid_data['label'] = valid_data['label'].apply(lambda x: str(x))\n",
    "print('训练集大小：',len(train_data))\n",
    "print('验证集大小：',len(valid_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "# args.tag2idx = {'O':0, 'B-0':1, 'I-0':2}\n",
    "# args.idx2tag = {0: 'O', 1: 'B-0', 2:'I-0'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ML_ENVS\\lib\\site-packages\\ark_nlp\\dataset\\base\\_dataset.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label'] = data['label'].apply(lambda x: str(x))\n",
      "F:\\ML_ENVS\\lib\\site-packages\\ark_nlp\\dataset\\base\\_token_classification_dataset.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['text'] = data_df['text'].apply(lambda x: x.strip())\n",
      "F:\\ML_ENVS\\lib\\site-packages\\ark_nlp\\dataset\\base\\_token_classification_dataset.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lambda x: eval(x) if type(x) == str else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained save_model use../pretrain_models/nezha-cn-base\n"
     ]
    }
   ],
   "source": [
    "label_list = ['0', 'O']\n",
    "\n",
    "\n",
    "train_dataset = Dt(train_data, categories=label_list)\n",
    "dev_dataset = Dt(valid_data, categories=label_list)\n",
    "print('pretrained save_model use'+args.bert_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_dir)\n",
    "ark_tokenizer = Tokenizer(vocab=tokenizer, max_seq_len=54)\n",
    "\n",
    "train_dataset.convert_to_ids(ark_tokenizer)\n",
    "dev_dataset.convert_to_ids(ark_tokenizer)\n",
    "\n",
    "\n",
    "Ent2id = train_dataset.cat2id\n",
    "id2Ent = train_dataset.id2cat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "({'0': 0, 'O': 1}, {0: '0', 1: 'O'})"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ent2id, id2Ent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 38\n"
     ]
    }
   ],
   "source": [
    "from data_helper import create_data_loader\n",
    "train_data_loader, valid_data_loader = create_data_loader(train_data_df=train_data,\n",
    "                                                          dev_data_df=valid_data,\n",
    "                                                          ark_tokenizer=ark_tokenizer,\n",
    "                                                          args=args,\n",
    "                                                          train_dataset=train_dataset,\n",
    "                                                          dev_dataset=dev_dataset,\n",
    "                                                          bert_tokenizer=tokenizer)\n",
    "\n",
    "print(len(train_data_loader), len(valid_data_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def jaccard_score(pred, label):\n",
    "    return len(set(pred) & set(label)) / len(set(pred) | set(label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, args, scheduler):\n",
    "    # 训练模式\n",
    "    model = model.train()\n",
    "    train_loss = 0\n",
    "    for token_id, at_mask, label_id, token_type_ids in tqdm(data_loader):\n",
    "        outputs = model(token_id.to(args.device), at_mask.to(args.device), token_type_ids.to(args.device))\n",
    "        loss = loss_fn(outputs, label_id.to(args.device))\n",
    "        train_loss+=loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # -----------------------------------对抗攻击------------------------------------------------\n",
    "        if args.use_fgm:\n",
    "            fgm.attack()\n",
    "            outputs = model(token_id.to(args.device), at_mask.to(args.device), token_type_ids.to(args.device))\n",
    "            loss_fgm = loss_fn(outputs, label_id.to(args.device)).mean()\n",
    "            loss_fgm.backward()\n",
    "            fgm.restore()\n",
    "        if args.use_pgd:\n",
    "            pgd.backup_grad()\n",
    "            for t in range(K):\n",
    "                pgd.attack(is_first_attack=(t == 0))\n",
    "                if t != K - 1:\n",
    "                    model.zero_grad()\n",
    "                else:\n",
    "                    pgd.restore_grad()\n",
    "                outputs = model(token_id.to(args.device), at_mask.to(args.device), token_type_ids.to(args.device))\n",
    "                loss_pgd = loss_fn(outputs, label_id.to(args.device)).mean()\n",
    "                loss_pgd.backward()\n",
    "            pgd.restore()\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "        if args.ema != False:\n",
    "            args.ema.update()\n",
    "\n",
    "\n",
    "\n",
    "    return train_loss/len(data_loader)\n",
    "\n",
    "\n",
    "def return_entity(label):\n",
    "    entity_labels = []\n",
    "    for _type, _start_idx, _end_idx in get_entity_bio(label, id2label=None):\n",
    "            entity_labels.append({\n",
    "                'start_idx': _start_idx,\n",
    "                'end_idx': _end_idx,\n",
    "                'type': _type\n",
    "            })\n",
    "    entity_labels = [str(dic['start_idx'])+'-'+str(dic['end_idx']) for dic in entity_labels]\n",
    "    return entity_labels\n",
    "\n",
    "\n",
    "def eval_epoch(model, data_loader, args):\n",
    "    # 验证模式\n",
    "    model = model.eval()\n",
    "    if args.ema!=False:\n",
    "        args.ema.apply_shadow()\n",
    "    val_loss = 0\n",
    "    jc_score_list = []\n",
    "    # 关闭自动求导，省内存加速，因为是不是训练模式了，没必要求导\n",
    "    with torch.no_grad():\n",
    "        for token_id, at_mask, label_id, token_type_ids in tqdm(data_loader):\n",
    "            outputs = model(token_id.to(args.device), at_mask.to(args.device), token_type_ids.to(args.device))\n",
    "            loss = loss_fn(outputs, label_id.to(args.device))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "            y_pred = outputs\n",
    "            y_true = label_id.to(args.device)\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "            y_true = y_true.cpu().numpy()\n",
    "            pred = []\n",
    "            true = []\n",
    "            for b, l, start, end in zip(*np.where(y_pred > 0)):\n",
    "                pred.append((b, l, start, end))\n",
    "            for b, l, start, end in zip(*np.where(y_true > 0)):\n",
    "                true.append((b, l, start, end))\n",
    "\n",
    "            jc_score_list.append(jaccard_score(pred=pred, label=true))\n",
    "\n",
    "    return val_loss/len(data_loader), np.mean(jc_score_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用： cuda:0  ing........\n",
      "batch_size:  16 epochs:  6\n",
      "learning_rate:  5e-05\n",
      "num_training_steps:  1800\n",
      "warmup_steps:  108.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrain_models/nezha-cn-base were not used when initializing NeZhaModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing NeZhaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NeZhaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ../pretrain_models/nezha-cn-base and are newly initialized: ['bert.encoder.layer.4.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.5.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.7.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.3.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.0.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.1.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.9.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.10.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.8.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.2.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.11.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.6.attention.self.relative_positions_encoding.positions_encoding']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    args.device = 'cuda:0'\n",
    "    print('使用：', args.device,' ing........')\n",
    "\n",
    "\n",
    "model = GlobalPointer(args, len(Ent2id), 64).to(args.device)  # (encoder, ent_type_size, inner_dim)\n",
    "\n",
    "\n",
    "print('batch_size: ',args.batch_size, 'epochs: ',args.max_epochs)\n",
    "num_total_steps = len(train_data_loader) * args.max_epochs\n",
    "from util import build_optimizer\n",
    "optimizer, scheduler = build_optimizer(args, model, num_total_steps=num_total_steps)\n",
    "loss_fn = GlobalPointerCrossEntropy().to(args.device)\n",
    "\n",
    "\n",
    "\n",
    "if args.ema==True:\n",
    "    print('-'*10,'采用EMA机制训练','-'*10)\n",
    "    from tricks import EMA\n",
    "    args.ema = EMA(model, 0.999)\n",
    "    args.ema.register()\n",
    "\n",
    "if args.use_fgm==True:\n",
    "    print('-' * 10, '采用FGM对抗训练', '-' * 10)\n",
    "    from tricks import FGM\n",
    "    # 初始化\n",
    "    fgm = FGM(model)\n",
    "\n",
    "if args.use_pgd==True:\n",
    "    print('-' * 10, '采用PGD对抗训练', '-' * 10)\n",
    "    from tricks import PGD\n",
    "    # 初始化\n",
    "    pgd = PGD(model=model)\n",
    "    K = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————————————————— Epoch 1/6 ————————————————————\n",
      "Train loss : 3.32\n",
      "\n",
      "val loss : 0.82\n",
      "jc_score: 0.648\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 2/6 ————————————————————\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_10612/441824232.py\", line 4, in <module>\n",
      "    train_loss = train_epoch(model, train_data_loader, optimizer, args, scheduler)\n",
      "  File \"C:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_10612/72103219.py\", line 35, in train_epoch\n",
      "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
      "  File \"F:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 43, in clip_grad_norm_\n",
      "    if total_norm.isnan() or total_norm.isinf():\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"F:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"F:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"F:\\ML_ENVS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"F:\\ML_ENVS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"F:\\ML_ENVS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"F:\\ML_ENVS\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"F:\\ML_ENVS\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"F:\\ML_ENVS\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"F:\\ML_ENVS\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]E:\\打工\\竞赛\\疫情新闻地理位置识别\\nezha+gp\\data_helper.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ark_data[index]['label_ids'].to_dense()), torch.tensor(self.ark_data[index]['token_type_ids'],\n",
      "100%|██████████| 300/300 [00:36<00:00,  8.27it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 13.56it/s]\n",
      " 46%|████▌     | 137/300 [00:18<00:21,  7.59it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_10612/441824232.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'——'\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mf'Epoch {epoch + 1}/{args.max_epochs}'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'——'\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mtrain_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_epoch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_data_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscheduler\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[1;31m# #scheduler.step()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_10612/72103219.py\u001B[0m in \u001B[0;36mtrain_epoch\u001B[1;34m(model, data_loader, optimizer, args, scheduler)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m         \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclip_grad_norm_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1.0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001B[0m in \u001B[0;36mclip_grad_norm_\u001B[1;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[0mtotal_norm\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mparameters\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[0mtotal_norm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misnan\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mtotal_norm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misinf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0merror_if_nonfinite\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2060\u001B[0m                         \u001B[1;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2061\u001B[1;33m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2062\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2062\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2063\u001B[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[1;32m-> 2064\u001B[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001B[0m\u001B[0;32m   2065\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2066\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_showtraceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1367\u001B[0m         return FormattedTB.structured_traceback(\n\u001B[1;32m-> 1368\u001B[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[0m\u001B[0;32m   1369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1370\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1266\u001B[0m             \u001B[1;31m# Verbose modes need a full traceback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1267\u001B[0m             return VerboseTB.structured_traceback(\n\u001B[1;32m-> 1268\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1269\u001B[0m             )\n\u001B[0;32m   1270\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'Minimal'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1123\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1124\u001B[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[1;32m-> 1125\u001B[1;33m                                                                tb_offset)\n\u001B[0m\u001B[0;32m   1126\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1127\u001B[0m         \u001B[0mcolors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mColors\u001B[0m  \u001B[1;31m# just a shorthand + quicker name lookup\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1082\u001B[1;33m         \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[1;34m(etype, value, records)\u001B[0m\n\u001B[0;32m    380\u001B[0m     \u001B[1;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    381\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m     \u001B[1;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "best_jc_score = 0\n",
    "for epoch in range(args.max_epochs):\n",
    "    print('——'*10, f'Epoch {epoch + 1}/{args.max_epochs}', '——'*10)\n",
    "    train_loss = train_epoch(model, train_data_loader, optimizer, args, scheduler)\n",
    "    # #scheduler.step()\n",
    "    # print('-'*20)\n",
    "    print(f'Train loss : {round(train_loss, 2)}\\n')\n",
    "    val_loss, jc_score = eval_epoch(model, valid_data_loader, args)\n",
    "\n",
    "\n",
    "\n",
    "    if jc_score>best_jc_score:\n",
    "        best_jc_score = jc_score\n",
    "        print(f'val loss : {round(val_loss, 3)}')\n",
    "        print(f\"jc_score: {round(jc_score, 3)}\")\n",
    "        print('-'*20)\n",
    "        torch.save(model.state_dict(), './save_model/best_model.pth')\n",
    "        print('+'*6,'best save_model saved','+'*6)\n",
    "\n",
    "    if args.ema != False:\n",
    "        args.ema.restore()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}