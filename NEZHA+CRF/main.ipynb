{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup,BertConfig\n",
    "from nezha import NeZhaConfig, NeZhaModel, NeZhaForMaskedLM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from config import parse_args\n",
    "\n",
    "args = parse_args()\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "setup_seed(args.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    6000 non-null   object\n",
      " 1   tag     6000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                         text          tag\n0   会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。       [会安古镇]\n1                                   贝蒂斯vs西班牙人  [贝蒂斯, 西班牙人]\n2        最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，        [橘子熊]\n3  2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing         [北京]\n4                        光谱代理《大战略PERFECT3》繁体版         [光谱]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。</td>\n      <td>[会安古镇]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>贝蒂斯vs西班牙人</td>\n      <td>[贝蒂斯, 西班牙人]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，</td>\n      <td>[橘子熊]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing</td>\n      <td>[北京]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>光谱代理《大战略PERFECT3》繁体版</td>\n      <td>[光谱]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../dataset/train.csv'\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "df['tag'] = df['tag'].apply(lambda x: eval(x))\n",
    "df.info()\n",
    "\n",
    "df.head(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:00<00:00, 120001.26it/s]\n"
     ]
    }
   ],
   "source": [
    "bio_list = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    text = df['text'][i]\n",
    "    tags = df['tag'][i]\n",
    "    bios = ['O']*len(text)\n",
    "    for t in tags:\n",
    "        idx = text.find(t)\n",
    "        bios[idx] = 'B-0'\n",
    "        for j in range(idx+1, idx+len(t)):\n",
    "            bios[j] = 'I-0'\n",
    "    bio_list.append(bios)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "bio_list = [' '.join(i) for i in bio_list]\n",
    "df['bio'] = bio_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19322 entries, 0 to 19321\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    19322 non-null  object\n",
      " 1   tag     19322 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 302.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                    text    tag\n0    2018年去南美区看世界杯得花多少钱?  [南美区]\n1  “产地办展”模式为“世界杯制造”送创新情报  [世界杯]\n2     加快产城融合 以科技创新引领英超建设   [英超]\n3          探秘、鸭绿江关东特大地震!  [鸭绿江]\n4        花旗区:让文明新风吹进千家万户   [花旗]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018年去南美区看世界杯得花多少钱?</td>\n      <td>[南美区]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>“产地办展”模式为“世界杯制造”送创新情报</td>\n      <td>[世界杯]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>加快产城融合 以科技创新引领英超建设</td>\n      <td>[英超]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>探秘、鸭绿江关东特大地震!</td>\n      <td>[鸭绿江]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>花旗区:让文明新风吹进千家万户</td>\n      <td>[花旗]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# extra_df = pd.read_csv('../阿里天池中文NLP预训练模型泛化能力评估数据集/TNEWS_train.csv')\n",
    "# extra_df = pd.read_csv('../阿里天池地址解析数据集/my_train.csv')\n",
    "# extra_df['tag'] = extra_df['tag'].apply(lambda x: eval(x))\n",
    "# extra_df['text'] = extra_df['text'].apply(lambda x: x.rstrip().rstrip('\\u200b').replace('\\u200b',' '))\n",
    "# extra_df.info()\n",
    "# \n",
    "# extra_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19322/19322 [00:00<00:00, 114329.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# extra_bio_list = []\n",
    "# for i in tqdm(range(len(extra_df))):\n",
    "#     text = extra_df['text'][i]\n",
    "#     tags = extra_df['tag'][i]\n",
    "#     bios = ['O']*len(text)\n",
    "#     for t in tags:\n",
    "#         idx = text.find(t)\n",
    "#         bios[idx] = 'B-0'\n",
    "#         for j in range(idx+1, idx+len(t)):\n",
    "#             bios[j] = 'I-0'\n",
    "# \n",
    "#     assert len(list(text))==len(bios)\n",
    "# \n",
    "#     extra_bio_list.append(bios)\n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# extra_bio_list = [' '.join(i) for i in extra_bio_list]\n",
    "# extra_df['bio'] = extra_bio_list\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         text          tag  \\\n0   会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。       [会安古镇]   \n1                                   贝蒂斯vs西班牙人  [贝蒂斯, 西班牙人]   \n2        最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，        [橘子熊]   \n3  2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing         [北京]   \n4                        光谱代理《大战略PERFECT3》繁体版         [光谱]   \n\n                                                 bio  \n0  O O O O O O O O O B-0 I-0 I-0 I-0 O O O O O O ...  \n1                    B-0 I-0 I-0 O O B-0 I-0 I-0 I-0  \n2  O O B-0 I-0 I-0 O O O O O O O O O O O O O O O ...  \n3  O O O O O O O O O O O O B-0 I-0 O O O O O O O ...  \n4        B-0 I-0 O O O O O O O O O O O O O O O O O O  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n      <th>bio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。</td>\n      <td>[会安古镇]</td>\n      <td>O O O O O O O O O B-0 I-0 I-0 I-0 O O O O O O ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>贝蒂斯vs西班牙人</td>\n      <td>[贝蒂斯, 西班牙人]</td>\n      <td>B-0 I-0 I-0 O O B-0 I-0 I-0 I-0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，</td>\n      <td>[橘子熊]</td>\n      <td>O O B-0 I-0 I-0 O O O O O O O O O O O O O O O ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing</td>\n      <td>[北京]</td>\n      <td>O O O O O O O O O O O O B-0 I-0 O O O O O O O ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>光谱代理《大战略PERFECT3》繁体版</td>\n      <td>[光谱]</td>\n      <td>B-0 I-0 O O O O O O O O O O O O O O O O O O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra_df.head(5)\n",
    "# df.head(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pd.concat([df1,df2],ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# x = extra_df.iloc[4997]\n",
    "# x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# x['bio']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# len(list(x['text'])), len(x['bio'].split(' '))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# list(x['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： 9800\n",
      "验证集大小： 1200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data = train_test_split(df, test_size = 0.2, random_state=args.seed)\n",
    "train_data.index = list(range(len(train_data)))\n",
    "# extra_df = extra_df[:5000]\n",
    "# train_data = pd.concat([train_data, extra_df], ignore_index=True)\n",
    "\n",
    "valid_data.index = list(range(len(valid_data)))\n",
    "# print(len(train_data), len(valid_data))\n",
    "print('训练集大小：',len(train_data))\n",
    "print('验证集大小：',len(valid_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "args.tag2idx = {'O':0, 'B-0':1, 'I-0':2}\n",
    "args.idx2tag = {0: 'O', 1: 'B-0', 2:'I-0'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "F:\\ML_ENVS\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained save_model use../pretrain_models/nezha-cn-base\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('pretrained save_model use'+args.bert_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_dir)\n",
    "\n",
    "from data_helper import create_data_loader\n",
    "train_data_loader = create_data_loader(train_data['text'], train_data['bio'], args, tokenizer)\n",
    "valid_data_loader = create_data_loader(valid_data['text'], valid_data['bio'], args, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613 75\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_loader), len(valid_data_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def jaccard_score(pred, label):\n",
    "    return len(set(pred) & set(label)) / len(set(pred) | set(label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, args, scheduler):\n",
    "    # 训练模式\n",
    "    model = model.train()\n",
    "    train_loss = 0\n",
    "    for sample in tqdm(data_loader):\n",
    "        input_ids = sample['input_ids'].to(args.device)\n",
    "        attention_mask = sample['attention_mask'].to(args.device)\n",
    "        label_ids = sample['label_ids'].to(args.device)\n",
    "        out, loss = model(input_ids=input_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        attention_mask=attention_mask)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # -----------------------------------对抗攻击------------------------------------------------\n",
    "        if args.use_fgm:\n",
    "            # 对抗训练\n",
    "            fgm.attack()  # 在embedding上添加对抗扰动\n",
    "            # loss_adv = model(batch_input, batch_label)\n",
    "            out, loss_adv = model(input_ids=input_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        attention_mask=attention_mask)\n",
    "            loss_adv = loss_adv.mean()\n",
    "            loss_adv.backward()  # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "            fgm.restore()  # 恢复embedding参数\n",
    "\n",
    "        if args.use_pgd:\n",
    "            pgd.backup_grad()\n",
    "            for t in range(K):\n",
    "                pgd.attack(is_first_attack=(t == 0))\n",
    "                if t != K - 1:\n",
    "                    model.zero_grad()\n",
    "                else:\n",
    "                    pgd.restore_grad()\n",
    "\n",
    "                out, loss_adv = model(input_ids=input_ids,\n",
    "                                      label_ids=label_ids,\n",
    "                                      attention_mask=attention_mask)\n",
    "                loss_adv = loss_adv.mean()\n",
    "                loss_adv.backward()  # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "\n",
    "            pgd.restore()\n",
    "\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "        if args.ema != False:\n",
    "            args.ema.update()\n",
    "\n",
    "\n",
    "\n",
    "    return train_loss/len(data_loader)\n",
    "\n",
    "from ark_nlp.factory.utils.conlleval import get_entity_bio\n",
    "def return_entity(label):\n",
    "    entity_labels = []\n",
    "    for _type, _start_idx, _end_idx in get_entity_bio(label, id2label=None):\n",
    "            entity_labels.append({\n",
    "                'start_idx': _start_idx,\n",
    "                'end_idx': _end_idx,\n",
    "                'type': _type\n",
    "            })\n",
    "    entity_labels = [str(dic['start_idx'])+'-'+str(dic['end_idx']) for dic in entity_labels]\n",
    "    return entity_labels\n",
    "\n",
    "\n",
    "def eval_epoch(model, data_loader, args):\n",
    "    # 验证模式\n",
    "    model = model.eval()\n",
    "    if args.ema!=False:\n",
    "        args.ema.apply_shadow()\n",
    "    val_loss = 0\n",
    "    jc_score_list = []\n",
    "    # 关闭自动求导，省内存加速，因为是不是训练模式了，没必要求导\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(data_loader):\n",
    "            input_ids = sample['input_ids'].to(args.device)\n",
    "            attention_mask = sample['attention_mask'].to(args.device)\n",
    "            label_ids = sample['label_ids'].to(args.device)\n",
    "            out, loss = model(input_ids=input_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        attention_mask=attention_mask)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "            predict_ids = out\n",
    "            # predict_ids\n",
    "            #%%\n",
    "            label_ids = sample['label_ids'].numpy().tolist()\n",
    "\n",
    "            entity_all_label_ids = []\n",
    "            entity_all_predict_ids = []\n",
    "            for i in range(len(label_ids)):\n",
    "                tmp_label, tmp_predict = [], []\n",
    "                # 因为我crf有做mask所以这里的len(len(predict_tag[i]))是不带有pad的长度\n",
    "                for j in range(0, len(predict_ids[i])):\n",
    "                    tmp_label.append(args.idx2tag[label_ids[i][j]])\n",
    "                    tmp_predict.append(args.idx2tag[predict_ids[i][j]])\n",
    "                entity_all_label_ids.append(tmp_label)\n",
    "                entity_all_predict_ids.append(tmp_predict)\n",
    "\n",
    "\n",
    "            for label, pred in zip(entity_all_label_ids, entity_all_predict_ids):\n",
    "                label_entity = return_entity(label)\n",
    "                pred_entity = return_entity(pred)\n",
    "                jc_score_list.append(jaccard_score(pred=pred_entity, label=label_entity))\n",
    "\n",
    "    return val_loss/len(data_loader), np.mean(jc_score_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用： cuda:0  ing........\n",
      "batch_size:  16 epochs:  6\n",
      "learning_rate:  5e-05\n",
      "num_training_steps:  3678\n",
      "warmup_steps:  220.67999999999998\n",
      "---------- 采用EMA机制训练 ----------\n",
      "---------- 采用FGM对抗训练 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrain_models/nezha-cn-base were not used when initializing NeZhaModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing NeZhaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NeZhaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ../pretrain_models/nezha-cn-base and are newly initialized: ['bert.encoder.layer.4.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.6.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.0.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.2.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.9.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.3.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.5.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.7.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.8.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.11.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.10.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.1.attention.self.relative_positions_encoding.positions_encoding']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from model import BERT_CRF\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    args.device = 'cuda:0'\n",
    "    print('使用：', args.device,' ing........')\n",
    "\n",
    "model = BERT_CRF(args=args).to(args.device)\n",
    "\n",
    "\n",
    "print('batch_size: ',args.batch_size, 'epochs: ',args.max_epochs)\n",
    "num_total_steps = len(train_data_loader) * args.max_epochs\n",
    "from util import build_optimizer, build_optimizer_diff_lr\n",
    "optimizer, scheduler = build_optimizer(args, model, num_total_steps=num_total_steps)\n",
    "# optimizer, scheduler = build_optimizer_diff_lr(args, model, num_total_steps=num_total_steps)\n",
    "\n",
    "\n",
    "\n",
    "if args.ema==True:\n",
    "    print('-'*10,'采用EMA机制训练','-'*10)\n",
    "    from tricks import EMA\n",
    "    args.ema = EMA(model, 0.995)\n",
    "    args.ema.register()\n",
    "\n",
    "if args.use_fgm==True:\n",
    "    print('-' * 10, '采用FGM对抗训练', '-' * 10)\n",
    "    from tricks import FGM\n",
    "    # 初始化\n",
    "    fgm = FGM(model)\n",
    "\n",
    "if args.use_pgd==True:\n",
    "    print('-' * 10, '采用PGD对抗训练', '-' * 10)\n",
    "    from tricks import PGD\n",
    "    # 初始化\n",
    "    pgd = PGD(model=model)\n",
    "    K = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————————————————— Epoch 1/6 ————————————————————\n",
      "Train loss : 102.84\n",
      "\n",
      "val loss : 86.103\n",
      "jc_score: 0.685\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 2/6 ————————————————————\n",
      "Train loss : 33.73\n",
      "\n",
      "val loss : 83.367\n",
      "jc_score: 0.718\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 3/6 ————————————————————\n",
      "Train loss : 19.78\n",
      "\n",
      "———————————————————— Epoch 4/6 ————————————————————\n",
      "Train loss : 12.62\n",
      "\n",
      "val loss : 101.338\n",
      "jc_score: 0.726\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 5/6 ————————————————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 613/613 [03:28<00:00,  2.93it/s]\n",
      "100%|██████████| 75/75 [00:05<00:00, 14.91it/s]\n",
      "100%|██████████| 613/613 [03:37<00:00,  2.82it/s]\n",
      "100%|██████████| 75/75 [00:05<00:00, 13.79it/s]\n",
      "100%|██████████| 613/613 [03:39<00:00,  2.79it/s]\n",
      "100%|██████████| 75/75 [00:05<00:00, 12.84it/s]\n",
      "100%|██████████| 613/613 [03:47<00:00,  2.69it/s]\n",
      "100%|██████████| 75/75 [00:05<00:00, 13.29it/s]\n",
      " 23%|██▎       | 143/613 [00:53<02:56,  2.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_13032/441824232.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_epochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'——'\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mf'Epoch {epoch + 1}/{args.max_epochs}'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'——'\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mtrain_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_epoch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_data_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscheduler\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[1;31m# #scheduler.step()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[1;31m# print('-'*20)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_13032/722385244.py\u001B[0m in \u001B[0;36mtrain_epoch\u001B[1;34m(model, data_loader, optimizer, args, scheduler)\u001B[0m\n\u001B[0;32m     23\u001B[0m                         attention_mask=attention_mask)\n\u001B[0;32m     24\u001B[0m             \u001B[0mloss_adv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss_adv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m             \u001B[0mloss_adv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# 反向传播，并在正常的grad基础上，累加对抗训练的梯度\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m             \u001B[0mfgm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrestore\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# 恢复embedding参数\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    253\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    254\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 255\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    256\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    257\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    147\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[0;32m    148\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 149\u001B[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001B[0m\u001B[0;32m    150\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "best_jc_score = 0\n",
    "for epoch in range(args.max_epochs):\n",
    "    print('——'*10, f'Epoch {epoch + 1}/{args.max_epochs}', '——'*10)\n",
    "    train_loss = train_epoch(model, train_data_loader, optimizer, args, scheduler)\n",
    "    # #scheduler.step()\n",
    "    # print('-'*20)\n",
    "    print(f'Train loss : {round(train_loss, 2)}\\n')\n",
    "    val_loss, jc_score = eval_epoch(model, valid_data_loader, args)\n",
    "\n",
    "\n",
    "\n",
    "    if jc_score>best_jc_score:\n",
    "        best_jc_score = jc_score\n",
    "        print(f'val loss : {round(val_loss, 3)}')\n",
    "        print(f\"jc_score: {round(jc_score, 3)}\")\n",
    "        print('-'*20)\n",
    "        torch.save(model.state_dict(), './save_model/best_model.pth')\n",
    "        print('+'*6,'best save_model saved','+'*6)\n",
    "\n",
    "    if args.ema != False:\n",
    "        args.ema.restore()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}