{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup,BertConfig\n",
    "from ark_nlp.model.ner.global_pointer_bert import Tokenizer\n",
    "from ark_nlp.model.ner.global_pointer_bert import Dataset as Dt\n",
    "from ark_nlp.factory.utils.conlleval import get_entity_bio\n",
    "from model import GlobalPointer, GlobalPointerNERPredictor, GlobalPointerCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from config import parse_args\n",
    "\n",
    "args = parse_args()\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "setup_seed(args.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    6000 non-null   object\n",
      " 1   tag     6000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                         text          tag\n0   会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。       [会安古镇]\n1                                   贝蒂斯vs西班牙人  [贝蒂斯, 西班牙人]\n2        最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，        [橘子熊]\n3  2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing         [北京]\n4                        光谱代理《大战略PERFECT3》繁体版         [光谱]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。</td>\n      <td>[会安古镇]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>贝蒂斯vs西班牙人</td>\n      <td>[贝蒂斯, 西班牙人]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，</td>\n      <td>[橘子熊]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing</td>\n      <td>[北京]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>光谱代理《大战略PERFECT3》繁体版</td>\n      <td>[光谱]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../dataset/train.csv'\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "df['tag'] = df['tag'].apply(lambda x: eval(x))\n",
    "df.info()\n",
    "\n",
    "df.head(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:00<00:00, 117641.29it/s]\n"
     ]
    }
   ],
   "source": [
    "bio_list = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    text = df['text'][i]\n",
    "    tags = df['tag'][i]\n",
    "    bios = ['O']*len(text)\n",
    "    for t in tags:\n",
    "        idx = text.find(t)\n",
    "        bios[idx] = 'B-0'\n",
    "        for j in range(idx+1, idx+len(t)):\n",
    "            bios[j] = 'I-0'\n",
    "    bio_list.append(bios)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# bio_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df['BIO'] = bio_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "all_entity_labels = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    entity_labels=[]\n",
    "    for _type, _start_idx, _end_idx in get_entity_bio(df['BIO'][i], id2label=None):\n",
    "        entity_labels.append({\n",
    "            'start_idx': _start_idx,\n",
    "            'end_idx': _end_idx,\n",
    "            'type': _type,\n",
    "            'entity': df['text'][i][_start_idx: _end_idx + 1]\n",
    "        })\n",
    "    all_entity_labels.append(entity_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df['label'] = all_entity_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         text  \\\n0   会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。   \n1                                   贝蒂斯vs西班牙人   \n2        最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，   \n3  2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing   \n4                        光谱代理《大战略PERFECT3》繁体版   \n\n                                                 BIO  \\\n0  [O, O, O, O, O, O, O, O, O, B-0, I-0, I-0, I-0...   \n1          [B-0, I-0, I-0, O, O, B-0, I-0, I-0, I-0]   \n2  [O, O, B-0, I-0, I-0, O, O, O, O, O, O, O, O, ...   \n3  [O, O, O, O, O, O, O, O, O, O, O, O, B-0, I-0,...   \n4  [B-0, I-0, O, O, O, O, O, O, O, O, O, O, O, O,...   \n\n                                               label  \n0  [{'start_idx': 9, 'end_idx': 12, 'type': '0', ...  \n1  [{'start_idx': 0, 'end_idx': 2, 'type': '0', '...  \n2  [{'start_idx': 2, 'end_idx': 4, 'type': '0', '...  \n3  [{'start_idx': 12, 'end_idx': 13, 'type': '0',...  \n4  [{'start_idx': 0, 'end_idx': 1, 'type': '0', '...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>BIO</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。</td>\n      <td>[O, O, O, O, O, O, O, O, O, B-0, I-0, I-0, I-0...</td>\n      <td>[{'start_idx': 9, 'end_idx': 12, 'type': '0', ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>贝蒂斯vs西班牙人</td>\n      <td>[B-0, I-0, I-0, O, O, B-0, I-0, I-0, I-0]</td>\n      <td>[{'start_idx': 0, 'end_idx': 2, 'type': '0', '...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，</td>\n      <td>[O, O, B-0, I-0, I-0, O, O, O, O, O, O, O, O, ...</td>\n      <td>[{'start_idx': 2, 'end_idx': 4, 'type': '0', '...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-0, I-0,...</td>\n      <td>[{'start_idx': 12, 'end_idx': 13, 'type': '0',...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>光谱代理《大战略PERFECT3》繁体版</td>\n      <td>[B-0, I-0, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n      <td>[{'start_idx': 0, 'end_idx': 1, 'type': '0', '...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['tag'], axis=1)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： 4800\n",
      "验证集大小： 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "F:\\ML_ENVS\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data = train_test_split(df, test_size = 0.2, random_state=args.seed)\n",
    "train_data.index = list(range(len(train_data)))\n",
    "valid_data.index = list(range(len(valid_data)))\n",
    "train_data['label'] = train_data['label'].apply(lambda x: str(x))\n",
    "valid_data['label'] = valid_data['label'].apply(lambda x: str(x))\n",
    "print('训练集大小：',len(train_data))\n",
    "print('验证集大小：',len(valid_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "# args.tag2idx = {'O':0, 'B-0':1, 'I-0':2}\n",
    "# args.idx2tag = {0: 'O', 1: 'B-0', 2:'I-0'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ML_ENVS\\lib\\site-packages\\ark_nlp\\dataset\\base\\_dataset.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label'] = data['label'].apply(lambda x: str(x))\n",
      "F:\\ML_ENVS\\lib\\site-packages\\ark_nlp\\dataset\\base\\_token_classification_dataset.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['text'] = data_df['text'].apply(lambda x: x.strip())\n",
      "F:\\ML_ENVS\\lib\\site-packages\\ark_nlp\\dataset\\base\\_token_classification_dataset.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lambda x: eval(x) if type(x) == str else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained save_model use../hfl/chinese-roberta-wwm-ext\n"
     ]
    }
   ],
   "source": [
    "label_list = ['0', 'O']\n",
    "\n",
    "\n",
    "train_dataset = Dt(train_data, categories=label_list)\n",
    "dev_dataset = Dt(valid_data, categories=label_list)\n",
    "print('pretrained save_model use'+args.bert_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_dir)\n",
    "ark_tokenizer = Tokenizer(vocab=tokenizer, max_seq_len=54)\n",
    "\n",
    "train_dataset.convert_to_ids(ark_tokenizer)\n",
    "dev_dataset.convert_to_ids(ark_tokenizer)\n",
    "\n",
    "\n",
    "Ent2id = train_dataset.cat2id\n",
    "id2Ent = train_dataset.id2cat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "({'0': 0, 'O': 1}, {0: '0', 1: 'O'})"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ent2id, id2Ent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 38\n"
     ]
    }
   ],
   "source": [
    "from data_helper import create_data_loader\n",
    "train_data_loader, valid_data_loader = create_data_loader(train_data_df=train_data,\n",
    "                                                          dev_data_df=valid_data,\n",
    "                                                          ark_tokenizer=ark_tokenizer,\n",
    "                                                          args=args,\n",
    "                                                          train_dataset=train_dataset,\n",
    "                                                          dev_dataset=dev_dataset,\n",
    "                                                          bert_tokenizer=tokenizer)\n",
    "\n",
    "print(len(train_data_loader), len(valid_data_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def jaccard_score(pred, label):\n",
    "    return len(set(pred) & set(label)) / len(set(pred) | set(label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, args, scheduler):\n",
    "    # 训练模式\n",
    "    model = model.train()\n",
    "    train_loss = 0\n",
    "    for token_id, at_mask, label_id, token_type_ids in tqdm(data_loader):\n",
    "        outputs = model(token_id.to(args.device), at_mask.to(args.device), token_type_ids.to(args.device))\n",
    "        loss = loss_fn(outputs, label_id.to(args.device))\n",
    "        train_loss+=loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # -----------------------------------对抗攻击------------------------------------------------\n",
    "        if args.use_fgm:\n",
    "            fgm.attack()\n",
    "            outputs = model(token_id.to(args.device), at_mask.to(args.device), token_type_ids.to(args.device))\n",
    "            loss_fgm = loss_fn(outputs, label_id.to(args.device)).mean()\n",
    "            loss_fgm.backward()\n",
    "            fgm.restore()\n",
    "        if args.use_pgd:\n",
    "            pgd.backup_grad()\n",
    "            for t in range(K):\n",
    "                pgd.attack(is_first_attack=(t == 0))\n",
    "                if t != K - 1:\n",
    "                    model.zero_grad()\n",
    "                else:\n",
    "                    pgd.restore_grad()\n",
    "                outputs = model(token_id.to(args.device), at_mask.to(args.device), token_type_ids.to(args.device))\n",
    "                loss_pgd = loss_fn(outputs, label_id.to(args.device)).mean()\n",
    "                loss_pgd.backward()\n",
    "            pgd.restore()\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "        if args.ema != False:\n",
    "            args.ema.update()\n",
    "\n",
    "\n",
    "\n",
    "    return train_loss/len(data_loader)\n",
    "\n",
    "\n",
    "def return_entity(label):\n",
    "    entity_labels = []\n",
    "    for _type, _start_idx, _end_idx in get_entity_bio(label, id2label=None):\n",
    "            entity_labels.append({\n",
    "                'start_idx': _start_idx,\n",
    "                'end_idx': _end_idx,\n",
    "                'type': _type\n",
    "            })\n",
    "    entity_labels = [str(dic['start_idx'])+'-'+str(dic['end_idx']) for dic in entity_labels]\n",
    "    return entity_labels\n",
    "\n",
    "\n",
    "def eval_epoch(model, data_loader, args):\n",
    "    # 验证模式\n",
    "    model = model.eval()\n",
    "    if args.ema!=False:\n",
    "        args.ema.apply_shadow()\n",
    "    val_loss = 0\n",
    "    jc_score_list = []\n",
    "    # 关闭自动求导，省内存加速，因为是不是训练模式了，没必要求导\n",
    "    with torch.no_grad():\n",
    "        for token_id, at_mask, label_id, token_type_ids in tqdm(data_loader):\n",
    "            outputs = model(token_id.to(args.device), at_mask.to(args.device), token_type_ids.to(args.device))\n",
    "            loss = loss_fn(outputs, label_id.to(args.device))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "            y_pred = outputs\n",
    "            y_true = label_id.to(args.device)\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "            y_true = y_true.cpu().numpy()\n",
    "            pred = []\n",
    "            true = []\n",
    "            for b, l, start, end in zip(*np.where(y_pred > 0)):\n",
    "                pred.append((b, l, start, end))\n",
    "            for b, l, start, end in zip(*np.where(y_true > 0)):\n",
    "                true.append((b, l, start, end))\n",
    "\n",
    "            jc_score_list.append(jaccard_score(pred=pred, label=true))\n",
    "\n",
    "    return val_loss/len(data_loader), np.mean(jc_score_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用： cuda:0  ing........\n",
      "batch_size:  16 epochs:  6\n",
      "learning_rate:  5e-05\n",
      "num_training_steps:  1800\n",
      "warmup_steps:  180.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    args.device = 'cuda:0'\n",
    "    print('使用：', args.device,' ing........')\n",
    "\n",
    "\n",
    "model = GlobalPointer(args, len(Ent2id), 64).to(args.device)  # (encoder, ent_type_size, inner_dim)\n",
    "\n",
    "\n",
    "print('batch_size: ',args.batch_size, 'epochs: ',args.max_epochs)\n",
    "num_total_steps = len(train_data_loader) * args.max_epochs\n",
    "from util import build_optimizer\n",
    "optimizer, scheduler = build_optimizer(args, model, num_total_steps=num_total_steps)\n",
    "loss_fn = GlobalPointerCrossEntropy().to(args.device)\n",
    "\n",
    "\n",
    "\n",
    "if args.ema==True:\n",
    "    print('-'*10,'采用EMA机制训练','-'*10)\n",
    "    from tricks import EMA\n",
    "    args.ema = EMA(model, 0.999)\n",
    "    args.ema.register()\n",
    "\n",
    "if args.use_fgm==True:\n",
    "    print('-' * 10, '采用FGM对抗训练', '-' * 10)\n",
    "    from tricks import FGM\n",
    "    # 初始化\n",
    "    fgm = FGM(model)\n",
    "\n",
    "if args.use_pgd==True:\n",
    "    print('-' * 10, '采用PGD对抗训练', '-' * 10)\n",
    "    from tricks import PGD\n",
    "    # 初始化\n",
    "    pgd = PGD(model=model)\n",
    "    K = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————————————————— Epoch 1/6 ————————————————————\n",
      "Train loss : 2.04\n",
      "\n",
      "val loss : 0.69\n",
      "jc_score: 0.688\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 2/6 ————————————————————\n",
      "Train loss : 0.56\n",
      "\n",
      "val loss : 0.63\n",
      "jc_score: 0.708\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 3/6 ————————————————————\n",
      "Train loss : 0.37\n",
      "\n",
      "val loss : 0.733\n",
      "jc_score: 0.73\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 4/6 ————————————————————\n",
      "Train loss : 0.24\n",
      "\n",
      "val loss : 0.855\n",
      "jc_score: 0.731\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 5/6 ————————————————————\n",
      "Train loss : 0.17\n",
      "\n",
      "val loss : 0.903\n",
      "jc_score: 0.733\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 6/6 ————————————————————\n",
      "Train loss : 0.11\n",
      "\n",
      "val loss : 1.064\n",
      "jc_score: 0.741\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]E:\\打工\\竞赛\\疫情新闻地理位置识别\\bert+gp\\data_helper.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.ark_data[index]['label_ids'].to_dense()), torch.tensor(self.ark_data[index]['token_type_ids'],\n",
      "100%|██████████| 300/300 [00:34<00:00,  8.67it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 14.04it/s]\n",
      "100%|██████████| 300/300 [00:40<00:00,  7.46it/s]\n",
      "100%|██████████| 38/38 [00:03<00:00, 12.28it/s]\n",
      "100%|██████████| 300/300 [00:47<00:00,  6.29it/s]\n",
      "100%|██████████| 38/38 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 300/300 [00:51<00:00,  5.78it/s]\n",
      "100%|██████████| 38/38 [00:03<00:00, 10.54it/s]\n",
      "100%|██████████| 300/300 [00:53<00:00,  5.64it/s]\n",
      "100%|██████████| 38/38 [00:03<00:00, 10.71it/s]\n",
      "100%|██████████| 300/300 [00:55<00:00,  5.38it/s]\n",
      "100%|██████████| 38/38 [00:04<00:00,  9.24it/s]\n"
     ]
    }
   ],
   "source": [
    "best_jc_score = 0\n",
    "for epoch in range(args.max_epochs):\n",
    "    print('——'*10, f'Epoch {epoch + 1}/{args.max_epochs}', '——'*10)\n",
    "    train_loss = train_epoch(model, train_data_loader, optimizer, args, scheduler)\n",
    "    # #scheduler.step()\n",
    "    # print('-'*20)\n",
    "    print(f'Train loss : {round(train_loss, 2)}\\n')\n",
    "    val_loss, jc_score = eval_epoch(model, valid_data_loader, args)\n",
    "\n",
    "\n",
    "\n",
    "    if jc_score>best_jc_score:\n",
    "        best_jc_score = jc_score\n",
    "        print(f'val loss : {round(val_loss, 3)}')\n",
    "        print(f\"jc_score: {round(jc_score, 3)}\")\n",
    "        print('-'*20)\n",
    "        torch.save(model.state_dict(), './save_model/best_model.pth')\n",
    "        print('+'*6,'best save_model saved','+'*6)\n",
    "\n",
    "    if args.ema != False:\n",
    "        args.ema.restore()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}