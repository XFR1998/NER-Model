{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup,BertConfig\n",
    "from nezha import NeZhaConfig, NeZhaModel, NeZhaForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from config import parse_args\n",
    "\n",
    "args = parse_args()\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "setup_seed(args.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    6000 non-null   object\n",
      " 1   tag     6000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                         text          tag\n0   会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。       [会安古镇]\n1                                   贝蒂斯vs西班牙人  [贝蒂斯, 西班牙人]\n2        最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，        [橘子熊]\n3  2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing         [北京]\n4                        光谱代理《大战略PERFECT3》繁体版         [光谱]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>会安博物馆等，漫步会安古镇各精致的工艺品店、品尝路边的小吃摊，体验当地的风土民情。</td>\n      <td>[会安古镇]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>贝蒂斯vs西班牙人</td>\n      <td>[贝蒂斯, 西班牙人]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>最终橘子熊在特种部队项目以7：2，跑跑卡丁车项目以7：1痛击曜越太阳神，</td>\n      <td>[橘子熊]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008年11月22日，北京的气温陡降到零下4度，但雍和宫星光现场里“beijing</td>\n      <td>[北京]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>光谱代理《大战略PERFECT3》繁体版</td>\n      <td>[光谱]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../dataset/train.csv'\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "df['tag'] = df['tag'].apply(lambda x: eval(x))\n",
    "df.info()\n",
    "\n",
    "df.head(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:00<00:00, 119996.11it/s]\n"
     ]
    }
   ],
   "source": [
    "bio_list = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    text = df['text'][i]\n",
    "    tags = df['tag'][i]\n",
    "    bios = ['O']*len(text)\n",
    "    for t in tags:\n",
    "        idx = text.find(t)\n",
    "        bios[idx] = 'B-0'\n",
    "        for j in range(idx+1, idx+len(t)):\n",
    "            bios[j] = 'I-0'\n",
    "    bio_list.append(bios)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "bio_list = [' '.join(i) for i in bio_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df['bio'] = bio_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： 4800\n",
      "验证集大小： 1200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data = train_test_split(df, test_size = 0.2, random_state=args.seed)\n",
    "train_data.index = list(range(len(train_data)))\n",
    "valid_data.index = list(range(len(valid_data)))\n",
    "# print(len(train_data), len(valid_data))\n",
    "print('训练集大小：',len(train_data))\n",
    "print('验证集大小：',len(valid_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "args.tag2idx = {'O':0, 'B-0':1, 'I-0':2}\n",
    "args.idx2tag = {0: 'O', 1: 'B-0', 2:'I-0'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "F:\\ML_ENVS\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained save_model use../pretrain_models/nezha-cn-base\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('pretrained save_model use'+args.nezha_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(args.nezha_dir)\n",
    "\n",
    "from data_helper import create_data_loader\n",
    "train_data_loader = create_data_loader(train_data['text'], train_data['bio'], args, tokenizer)\n",
    "valid_data_loader = create_data_loader(valid_data['text'], valid_data['bio'], args, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 75\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_loader), len(valid_data_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def jaccard_score(pred, label):\n",
    "    return len(set(pred) & set(label)) / len(set(pred) | set(label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, args, scheduler):\n",
    "    # 训练模式\n",
    "    model = model.train()\n",
    "    train_loss = 0\n",
    "    for sample in tqdm(data_loader):\n",
    "        input_ids = sample['input_ids'].to(args.device)\n",
    "        attention_mask = sample['attention_mask'].to(args.device)\n",
    "        label_ids = sample['label_ids'].to(args.device)\n",
    "        out, loss = model(input_ids=input_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        attention_mask=attention_mask)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # -----------------------------------对抗攻击------------------------------------------------\n",
    "        if args.use_fgm:\n",
    "            # 对抗训练\n",
    "            fgm.attack()  # 在embedding上添加对抗扰动\n",
    "            # loss_adv = model(batch_input, batch_label)\n",
    "            out, loss_adv = model(input_ids=input_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        attention_mask=attention_mask)\n",
    "            loss_adv = loss_adv.mean()\n",
    "            loss_adv.backward()  # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "            fgm.restore()  # 恢复embedding参数\n",
    "\n",
    "        if args.use_pgd:\n",
    "            pgd.backup_grad()\n",
    "            for t in range(K):\n",
    "                pgd.attack(is_first_attack=(t == 0))\n",
    "                if t != K - 1:\n",
    "                    model.zero_grad()\n",
    "                else:\n",
    "                    pgd.restore_grad()\n",
    "\n",
    "                out, loss_adv = model(input_ids=input_ids,\n",
    "                                      label_ids=label_ids,\n",
    "                                      attention_mask=attention_mask)\n",
    "                loss_adv = loss_adv.mean()\n",
    "                loss_adv.backward()  # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "\n",
    "            pgd.restore()\n",
    "\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "        if args.ema != False:\n",
    "            args.ema.update()\n",
    "\n",
    "\n",
    "\n",
    "    return train_loss/len(data_loader)\n",
    "\n",
    "from ark_nlp.factory.utils.conlleval import get_entity_bio\n",
    "def return_entity(label):\n",
    "    entity_labels = []\n",
    "    for _type, _start_idx, _end_idx in get_entity_bio(label, id2label=None):\n",
    "            entity_labels.append({\n",
    "                'start_idx': _start_idx,\n",
    "                'end_idx': _end_idx,\n",
    "                'type': _type\n",
    "            })\n",
    "    entity_labels = [str(dic['start_idx'])+'-'+str(dic['end_idx']) for dic in entity_labels]\n",
    "    return entity_labels\n",
    "\n",
    "\n",
    "def eval_epoch(model, data_loader, args):\n",
    "    # 验证模式\n",
    "    model = model.eval()\n",
    "    if args.ema!=False:\n",
    "        args.ema.apply_shadow()\n",
    "    val_loss = 0\n",
    "    jc_score_list = []\n",
    "    # 关闭自动求导，省内存加速，因为是不是训练模式了，没必要求导\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(data_loader):\n",
    "            input_ids = sample['input_ids'].to(args.device)\n",
    "            attention_mask = sample['attention_mask'].to(args.device)\n",
    "            label_ids = sample['label_ids'].to(args.device)\n",
    "            out, loss = model(input_ids=input_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        attention_mask=attention_mask)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "            predict_ids = out\n",
    "            # predict_ids\n",
    "            #%%\n",
    "            label_ids = sample['label_ids'].numpy().tolist()\n",
    "\n",
    "            entity_all_label_ids = []\n",
    "            entity_all_predict_ids = []\n",
    "            for i in range(len(label_ids)):\n",
    "                tmp_label, tmp_predict = [], []\n",
    "                # 因为我crf有做mask所以这里的len(len(predict_tag[i]))是不带有pad的长度\n",
    "                for j in range(0, len(predict_ids[i])):\n",
    "                    tmp_label.append(args.idx2tag[label_ids[i][j]])\n",
    "                    tmp_predict.append(args.idx2tag[predict_ids[i][j]])\n",
    "                entity_all_label_ids.append(tmp_label)\n",
    "                entity_all_predict_ids.append(tmp_predict)\n",
    "\n",
    "\n",
    "            for label, pred in zip(entity_all_label_ids, entity_all_predict_ids):\n",
    "                label_entity = return_entity(label)\n",
    "                pred_entity = return_entity(pred)\n",
    "                jc_score_list.append(jaccard_score(pred=pred_entity, label=label_entity))\n",
    "\n",
    "    return val_loss/len(data_loader), np.mean(jc_score_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用： cuda:0  ing........\n",
      "batch_size:  16 epochs:  6\n",
      "learning_rate:  5e-05\n",
      "num_training_steps:  1800\n",
      "warmup_steps:  108.0\n",
      "---------- 采用EMA机制训练 ----------\n",
      "---------- 采用FGM对抗训练 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrain_models/nezha-cn-base were not used when initializing NeZhaModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing NeZhaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NeZhaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ../pretrain_models/nezha-cn-base and are newly initialized: ['bert.encoder.layer.1.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.2.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.11.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.10.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.5.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.9.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.7.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.0.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.3.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.8.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.6.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.4.attention.self.relative_positions_encoding.positions_encoding']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from model import BERT_CRF\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    args.device = 'cuda:0'\n",
    "    print('使用：', args.device,' ing........')\n",
    "\n",
    "model = BERT_CRF(args=args).to(args.device)\n",
    "\n",
    "\n",
    "print('batch_size: ',args.batch_size, 'epochs: ',args.max_epochs)\n",
    "num_total_steps = len(train_data_loader) * args.max_epochs\n",
    "from util import build_optimizer, build_optimizer_diff_lr\n",
    "optimizer, scheduler = build_optimizer(args, model, num_total_steps=num_total_steps)\n",
    "# optimizer, scheduler = build_optimizer_diff_lr(args, model, num_total_steps=num_total_steps)\n",
    "\n",
    "\n",
    "\n",
    "if args.ema==True:\n",
    "    print('-'*10,'采用EMA机制训练','-'*10)\n",
    "    from tricks import EMA\n",
    "    args.ema = EMA(model, 0.995)\n",
    "    args.ema.register()\n",
    "\n",
    "if args.use_fgm==True:\n",
    "    print('-' * 10, '采用FGM对抗训练', '-' * 10)\n",
    "    from tricks import FGM\n",
    "    # 初始化\n",
    "    fgm = FGM(model)\n",
    "\n",
    "if args.use_pgd==True:\n",
    "    print('-' * 10, '采用PGD对抗训练', '-' * 10)\n",
    "    from tricks import PGD\n",
    "    # 初始化\n",
    "    pgd = PGD(model=model)\n",
    "    K = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————————————————— Epoch 1/6 ————————————————————\n",
      "Train loss : 147.59\n",
      "\n",
      "val loss : 95.906\n",
      "jc_score: 0.687\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 2/6 ————————————————————\n",
      "Train loss : 53.47\n",
      "\n",
      "val loss : 66.607\n",
      "jc_score: 0.779\n",
      "--------------------\n",
      "++++++ best save_model saved ++++++\n",
      "———————————————————— Epoch 3/6 ————————————————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:45<00:00,  2.85it/s]\n",
      "100%|██████████| 75/75 [00:05<00:00, 14.42it/s]\n",
      "100%|██████████| 300/300 [01:54<00:00,  2.62it/s]\n",
      "100%|██████████| 75/75 [00:05<00:00, 13.93it/s]\n",
      " 43%|████▎     | 129/300 [00:50<01:02,  2.72it/s]"
     ]
    }
   ],
   "source": [
    "best_jc_score = 0\n",
    "for epoch in range(args.max_epochs):\n",
    "    print('——'*10, f'Epoch {epoch + 1}/{args.max_epochs}', '——'*10)\n",
    "    train_loss = train_epoch(model, train_data_loader, optimizer, args, scheduler)\n",
    "    # #scheduler.step()\n",
    "    # print('-'*20)\n",
    "    print(f'Train loss : {round(train_loss, 2)}\\n')\n",
    "    val_loss, jc_score = eval_epoch(model, valid_data_loader, args)\n",
    "\n",
    "\n",
    "\n",
    "    if jc_score>best_jc_score:\n",
    "        best_jc_score = jc_score\n",
    "        print(f'val loss : {round(val_loss, 3)}')\n",
    "        print(f\"jc_score: {round(jc_score, 3)}\")\n",
    "        print('-'*20)\n",
    "        torch.save(model.state_dict(), './save_model/best_model.pth')\n",
    "        print('+'*6,'best save_model saved','+'*6)\n",
    "\n",
    "    if args.ema != False:\n",
    "        args.ema.restore()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}